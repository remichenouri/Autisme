# -*- coding: utf-8 -*-
"""Streamlit-Autisme

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sp4gZneIBdWGe1iegQoyjSxAssashuQd
"""

!pip install -q streamlit pandas scikit-learn joblib
!pip install streamlit-shap shap
!pip install -q streamlit pyngrok
!pip install -q prince
from pyngrok import ngrok
ngrok.set_auth_token('2x7k3B4rM4RvdVemTEmJfcJOzx0_4UAtKKPM49PWF8LDBwTMT')

!mkdir -p pages

# Commented out IPython magic to ensure Python compatibility.
# %%writefile Streamlit-Autisme.py
# from io import BytesIO
# from lightgbm import LGBMClassifier
# from PIL import Image
# from scipy.stats import chi2_contingency, mannwhitneyu
# from sklearn.compose import ColumnTransformer
# from sklearn.ensemble import RandomForestClassifier
# from sklearn.linear_model import LogisticRegression
# from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report
# from sklearn.model_selection import cross_val_score
# from sklearn.model_selection import train_test_split
# from sklearn.pipeline import Pipeline
# from sklearn.preprocessing import StandardScaler, OneHotEncoder
# from xgboost import XGBClassifier
# import base64
# import matplotlib.pyplot as plt
# import numpy as np
# import os
# import pandas as pd
# import pickle
# import plotly.express as px
# import plotly.graph_objects as go
# import prince
# import requests
# import seaborn as sns
# import streamlit as st
# 
# 
# def get_img_with_href(img_url, target_url, as_banner=False):
#     # Extraire l'ID du fichier de l'URL Google Drive
#     if "drive.google.com" in img_url and "/d/" in img_url:
#         file_id = img_url.split("/d/")[1].split("/")[0]
#         img_url = f"https://drive.google.com/uc?export=view&id={file_id}"
# 
#     try:
#         # T√©l√©charger l'image avec un timeout explicite
#         response = requests.get(img_url, timeout=10)
#         response.raise_for_status()
# 
#         # V√©rifier la taille du contenu
#         if len(response.content) == 0:
#             raise Exception("Contenu vide t√©l√©charg√©")
# 
#         # Tenter d'ouvrir l'image avec diff√©rents formats
#         img = Image.open(BytesIO(response.content))
# 
#         # Convertir l'image en base64
#         buffered = BytesIO()
#         img.save(buffered, format="PNG")
#         img_str = base64.b64encode(buffered.getvalue()).decode()
# 
#         # AM√âLIORATION: Style pour que l'image s'adapte correctement au conteneur
#         if as_banner:
#             style = 'style="width:100%;height:550px;display:block;object-fit:cover;border-radius:10px;"'
#         else:
#             style = 'style="width:100%;height:auto;display:block;object-fit:contain;margin:0 auto;padding:0;"'
#         container_style = 'style="width:100%; padding:10px; background-color:white; border-radius:10px; overflow:hidden; margin-bottom:20px;"'
#         html_code = f'<div {container_style}><a href="{target_url}" target="_blank" style="display:block; margin:0; padding:0; line-height:0;"><img src="data:image/png;base64,{img_str}" {style}></a></div>'
#         return html_code
# 
# 
#         # Cr√©er le HTML avec un div conteneur √† dimensionnement fixe
#         container_style = 'style="width:100%; padding:10px; background-color:white; border-radius:10px; overflow:hidden; margin-bottom:20px;"'
# 
#         # HTML am√©lior√© avec div conteneur pour mieux contr√¥ler les dimensions
#         html_code = f'<div {container_style}><a href="{target_url}" target="_blank" style="display:block; margin:0; padding:0; line-height:0;"><img src="data:image/png;base64,{img_str}" {style}></a></div>'
#         return html_code
#     except Exception as e:
#         st.error(f"Erreur lors du chargement de l'image: {str(e)}")
#         # Image de remplacement
#         st.markdown('<div style="text-align: center; margin: 30px; padding: 50px; background-color: #f0f2f6; border-radius: 10px;"><p style="font-size: 1.2rem;">Image non disponible - Veuillez v√©rifier l\'URL</p></div>', unsafe_allow_html=True)
#         return ""
# 
# 
# 
#     except Exception as e:
#         st.error(f"Erreur lors du chargement de l'image: {str(e)}")
#         # Image de remplacement
#         st.markdown("""
#         <div style="text-align: center; margin: 30px; padding: 50px; background-color: #f0f2f6; border-radius: 10px;">
#             <p style="font-size: 1.2rem;">Image non disponible - Veuillez v√©rifier l'URL</p>
#         </div>
#         """, unsafe_allow_html=True)
#         return ""
# 
# def get_question_text(question_number):
#     questions_text = {
#         1: "Je remarque souvent de petits bruits que les autres ne remarquent pas.",
#         2: "Je me concentre g√©n√©ralement davantage sur l'ensemble que sur les petits d√©tails.",
#         3: "Je trouve facile de faire plusieurs choses en m√™me temps.",
#         4: "S'il y a une interruption, je peux rapidement reprendre ce que je faisais.",
#         5: "Je trouve facile de ¬´ lire entre les lignes ¬ª quand quelqu'un me parle.",
#         6: "Je sais comment savoir si la personne qui m'√©coute commence √† s'ennuyer.",
#         7: "Quand je lis une histoire, j'ai du mal √† comprendre les intentions des personnages.",
#         8: "J'aime collecter des informations sur des cat√©gories de choses.",
#         9: "Je trouve facile de comprendre ce que quelqu'un pense ou ressent rien qu'en regardant son visage.",
#         10: "J'ai du mal √† comprendre les intentions des gens."
#     }
#     return questions_text.get(question_number, "Question non d√©finie")
# 
# # Configuration de la page
# st.set_page_config(
#     page_title="D√©pistage Autisme",
#     page_icon="üß©",
#     layout="wide",
#     initial_sidebar_state="expanded"
# )
# 
# def set_custom_theme():
#     custom_theme = """
#     <style>
#     /* Variables globales */
#     :root {
#         --primary: #3498db;
#         --secondary: #2ecc71;
#         --background: #f0f2f6;
#         --card-bg: white;
#         --text: #2c3e50;
#     }
# 
#     /* Styles g√©n√©raux du conteneur */
#     [data-testid="stAppViewContainer"] {
#         background-color: var(--background);
#     }
# 
#     h1, h2, h3, h4, h5, h6 {
#         color: var(--text);
#         font-weight: 600;
#         font-family: 'Segoe UI', sans-serif;
#     }
# 
#     /* Correction de la navigation - SOLUTION PRINCIPALE */
#     [data-testid="stSidebar"] {
#         background-color: #f5f7fa;
#         border-right: 2px solid var(--primary);
#         padding-top: 2rem;
#         width: 250px !important; /* Largeur augment√©e */
#     }
#     [data-testid="stSidebar"] label {
#     margin-bottom: 14px !important;
#     padding: 8px 12px !important;
#     border-radius: 8px;
#     transition: background 0.2s;
#     }
#     [data-testid="stSidebar"] label:hover {
#         background: #eaf2f8 !important;
#     }
#     .sidebar-title {
#         margin-bottom: 2rem !important;
#     }
# 
# 
#     /* Assurer que le contenu est correctement dimensionn√© */
#     [data-testid="stSidebarContent"] {
#         width: 100%;
#         overflow: auto;
#         background-color: #f5f7fa !important;
#     }
# 
#     /* Am√©lioration du texte dans la sidebar */
#     [data-testid="stSidebar"] label,
#     [data-testid="stSidebar"] div,
#     [data-testid="stSidebar"] p,
#     [data-testid="stSidebar"] span {
#         color: #2c3e50 !important;
#         font-weight: 500 !important;
#         font-size: 1rem !important;
#         white-space: normal !important;
#         overflow-wrap: break-word !important;
#         word-wrap: break-word !important;
#     }
# 
#     /* Am√©lioration sp√©cifique pour les expanders */
#     [data-testid="stSidebar"] .streamlit-expanderHeader {
#         white-space: normal !important;
#         overflow-wrap: break-word !important;
#         word-wrap: break-word !important;
#         hyphens: auto !important;
#         padding-right: 10px !important;
#     }
# 
#     /* Titre de la sidebar plus visible */
#     .sidebar-title {
#         font-size: 1.5rem;
#         color: #3498db;
#         margin-bottom: 1.5rem;
#         text-align: center;
#         border-bottom: 2px solid #3498db;
#         padding-bottom: 0.5rem;
#     }
# 
#     /* Am√©lioration pour le menu de radiobuttons */
#     [data-testid="stSidebar"] div[role="radiogroup"] label {
#         color: #2c3e50 !important;
#         font-weight: 500 !important;
#         font-size: 0.95rem !important;
#         margin-bottom: 5px !important;
#         white-space: normal !important;
#         overflow-wrap: break-word !important;
#         line-height: 1.4 !important;
#         padding: 5px 10px !important;
#         display: block !important;
#         width: 100% !important;
#     }
# 
#     .sidebar .sidebar-content {
#         background-color: #f5f7fa !important;
#         border-right: 2px solid #3498db !important;
#     }
# 
#     .sidebar .sidebar-content .streamlit-expanderHeader,
#     .sidebar .sidebar-content label,
#     .sidebar .sidebar-content div,
#     .sidebar .sidebar-content p,
#     .sidebar .sidebar-content span {
#         color: #2c3e50 !important;
#         font-weight: 500 !important;
#     }
# 
#     .sidebar .sidebar-content label {
#         color: #2c3e50 !important;
#         font-weight: 500 !important;
#         font-size: 1rem !important;
#     }
# 
#     /* Styles des cartes et conteneurs */
#     .header-container {
#         display: flex;
#         align-items: center;
#         background: linear-gradient(90deg, var(--primary), var(--secondary));
#         padding: 1.5rem;
#         border-radius: 10px;
#         color: white;
#         margin-bottom: 1.5rem;
#     }
# 
#     .app-title {
#         font-size: 2.2rem;
#         font-weight: bold;
#         margin-left: 1rem;
#     }
# 
#     .puzzle-title {
#         display: flex;
#         align-items: center;
#         gap: 15px;
#         font-size: 2.2rem;
#         color: var(--primary);
#         font-weight: bold;
#         margin-bottom: 1rem;
#     }
# 
#     .puzzle-icon {
#         font-size: 2.2rem;
#     }
# 
#     .main .block-container {
#         padding-top: 0.7rem !important;
#         padding-bottom: 0.7rem !important;
#     }
# 
#     [data-testid="stVerticalBlock"] {
#         gap: 0.5rem !important;
#     }
# 
#     .element-container {
#         margin-bottom: 0.5rem !important;
#     }
# 
#     .css-1544g2n.e1fqkh3o4 {
#         padding-top: 2rem !important;
#         padding-bottom: 0.5rem !important;
#     }
# 
#     /* Styles des info-cards */
#     .info-card {
#         background-color: var(--card-bg);
#         border-radius: 12px;
#         padding: 1rem !important;
#         box-shadow: 0 6px 16px rgba(0, 0, 0, 0.1);
#         transition: transform 0.3s ease, box-shadow 0.3s ease;
#         border-top: 5px solid var(--primary);
#         margin-bottom: 10px !important;
#     }
# 
#     .info-card:hover {
#         transform: translateY(-5px);
#         box-shadow: 0 12px 20px rgba(0, 0, 0, 0.15);
#     }
# 
#     .card-title {
#         color: var(--primary);
#         font-size: 1.4rem;
#         font-weight: bold;
#         margin-bottom: 1rem;
#         border-bottom: 2px solid var(--primary);
#         padding-bottom: 0.5rem;
#     }
# 
#     /* Styles des questions et formulaires */
#     .question-container {
#         background-color: white;
#         padding: 12px 15px !important;
#         border-radius: 12px;
#         margin-bottom: 12px !important;
#         box-shadow: 0 3px 10px rgba(0,0,0,0.08);
#         border-left: 4px solid var(--primary);
#         transition: transform 0.2s ease, box-shadow 0.2s ease;
#     }
# 
#     .question-container:hover {
#         transform: translateY(-3px);
#         box-shadow: 0 5px 15px rgba(0,0,0,0.1);
#     }
# 
#     .question-text {
#         font-size: 1.1rem;
#         font-weight: 500;
#         color: var(--text);
#         margin-bottom: 15px;
#         line-height: 1.5;
#     }
# 
#     .questionnaire-title {
#         color: var(--primary);
#         font-size: 2rem;
#         margin-bottom: 2rem;
#         padding-bottom: 0.8rem;
#         border-bottom: 2px solid var(--primary);
#     }
# 
#     /* Styles des radiobuttons */
#     div[role="radiogroup"] {
#         display: flex;
#         flex-direction: row;
#         flex-wrap: wrap;
#         gap: 5px !important;
#         margin-top: 10px;
#         margin-bottom: 15px !important;
#     }
# 
#     div[role="radiogroup"] label {
#     color: #2c3e50 !important;  /* Texte fonc√© */
#     padding-right: 15px !important;
#     margin-bottom: 5px !important;
#     font-weight: 500 !important;
#     font-size: 1rem !important;
#     white-space: normal !important;
#     overflow-wrap: break-word !important;
#     line-height: 1.4 !important;
#     padding: 5px 10px !important;
#     display: block !important;
#     width: 100% !important;
# }
# 
# 
#     div[role="radiogroup"] label > div:first-child {
#         display: none !important;
#     }
# 
#     input[type="radio"] + div {
#         background: #f5f7fa !important;
#         color: var(--text);
#         border-radius: 38px !important;
#         padding: 10px 20px !important;
#         border: 1px solid #dfe4ea;
#         transition: all 0.3s ease;
#         font-weight: 500;
#     }
# 
# 
#     input[type="radio"] + div:hover {
#         background: #e9f0ff !important;
#         border-color: var(--primary);
#         transform: translateY(-1px);
#     }
# 
#     /* Styles des boutons et CTA */
#     .cta-button {
#         background: linear-gradient(135deg, var(--primary), #2980b9);
#         color: white;
#         padding: 0.9rem 1.5rem;
#         border-radius: 30px;
#         font-weight: bold;
#         text-align: center;
#         display: inline-block;
#         text-decoration: none;
#         transition: all 0.3s ease;
#         box-shadow: 0 4px 10px rgba(52, 152, 219, 0.3);
#         width: 80%;
#     }
# 
#     .cta-button:hover {
#         background: linear-gradient(135deg, #2980b9, var(--primary));
#         box-shadow: 0 6px 15px rgba(52, 152, 219, 0.4);
#         transform: translateY(-2px);
#     }
# 
#     .stButton > button {
#         width: 100%;
#         padding: 0.8rem 1rem !important;
#         font-size: 1.1rem !important;
#         margin-top: 1rem;
#     }
# 
#     /* Styles des expanders et tabs */
#     .streamlit-expanderHeader {
#         background-color: #f5f7fa;
#         border-radius: 8px;
#         font-weight: 600;
#         padding: 10px 15px !important;
#         border-left: 4px solid var(--primary);
#         transition: all 0.2s ease;
#     }
# 
#     .streamlit-expanderHeader:hover {
#         background-color: #eef1f5;
#         transform: translateX(2px);
#     }
# 
#     .stTabs [data-baseweb="tab-list"] {
#         gap: 2px;
#     }
# 
#     .stTabs [data-baseweb="tab"] {
#         height: 40px;
#         white-space: pre-wrap;
#         background-color: #f5f7fa;
#         border-radius: 5px 5px 0 0;
#         gap: 1px;
#         padding-left: 15px;
#         padding-right: 15px;
#     }
# 
#     .stTabs [aria-selected="true"] {
#         background-color: var(--primary) !important;
#         color: white !important;
#     }
# 
#     /* Styles divers */
#     [data-testid="stDataFrame"] {
#         border-radius: 8px;
#         overflow: hidden;
#         box-shadow: 0 2px 8px rgba(0,0,0,0.05);
#     }
# 
#     [data-testid="stMetricValue"] {
#         font-weight: 600;
#         color: var(--primary);
#         font-size: 1.2rem;
#     }
# 
#     [data-testid="stMetricDelta"] {
#         font-size: 0.9rem;
#     }
# 
#     div[data-baseweb="select"] > div {
#         border-radius: 8px;
#         background-color: white;
#         transition: all 0.2s ease;
#     }
# 
#     div[data-baseweb="select"] > div:hover {
#         border-color: var(--primary);
#     }
# 
#     pre {
#         white-space: pre-wrap;
#         word-wrap: break-word;
#         overflow-wrap: break-word;
#         overflow-x: auto;
#         max-width: 100%;
#         font-size: 0.9rem;
#         color: #2c3e50;
#     }
# 
#     .structure-donnees pre {
#         background-color: #ffffff;
#         padding: 15px;
#         border-radius: 5px;
#         font-family: 'Courier New', monospace;
#         border: 1px solid #d0d0d0;
#         line-height: 1.6;
#         box-shadow: 0 2px 4px rgba(0,0,0,0.05);
#     }
# 
#     .fade-in {
#         animation: fadeIn 0.8s ease-in-out;
#     }
# 
#     @keyframes fadeIn {
#         from { opacity: 0; transform: translateY(10px); }
#         to { opacity: 1; transform: translateY(0); }
#     }
# 
#     .footer {
#         background-color: #f0f2f6;
#         padding: 1rem;
#         text-align: center;
#         border-top: 2px solid #3498db;
#         margin-top: 2rem;
#         border-radius: 10px;
#     }
# 
#     .sidebar .sidebar-content .streamlit-expanderHeader {
#         white-space: normal !important;
#         overflow-wrap: break-word !important;
#         word-wrap: break-word !important;
#         hyphens: auto !important;
#         padding-right: 10px !important;
#     }
# 
#     .sidebar .sidebar-content label {
#         color: #2c3e50 !important;
#         font-weight: 500 !important;
#         font-size: 1rem !important;
#     }
# 
#     .sidebar .sidebar-content div[role="radiogroup"] label {
#         padding-right: 15px !important;
#         margin-bottom: 5px !important;
#         display: block !important;
#         width: 100% !important;
#     }
# 
#     [data-testid="stSidebar"][aria-expanded="true"] > div:first-child {
#         width: 320px;
#         min-width: 320px;
#     }
#     [data-testid="stSidebar"][aria-expanded="false"] > div:first-child {
#         width: 320px;
#         min-width: 320px;
#     }
# 
# 
#     [data-testid="stSidebar"] .css-1wvake5,
#     [data-testid="stSidebar"] .css-1v0mbdj,
#     [data-testid="stSidebar"] label {
#         white-space: normal !important;
#         word-break: break-word !important;
#         font-size: 1.1rem !important;
#         font-weight: 500 !important;
#         padding: 8px 14px !important;
#         margin-bottom: 10px !important;
#         border-radius: 8px;
#         color: #2c3e50 !important;
#         background: none !important;
#         transition: background 0.2s;
#         display: block;
#     }
# 
# 
#     [data-testid="stSidebar"] .css-1wvake5[aria-checked="true"],
#     [data-testid="stSidebar"] .css-1v0mbdj[aria-checked="true"],
#     [data-testid="stSidebar"] label[data-selected="true"] {
#         background: linear-gradient(90deg, #eaf6fb 60%, #e0f7fa 100%) !important;
#         color: #0077b6 !important;
#     }
# 
# 
#     [data-testid="stSidebar"] svg {
#         margin-right: 10px;
#         vertical-align: middle;
#     }
#     </style>
#     """
#     st.markdown(custom_theme, unsafe_allow_html=True)
# 
# 
# 
# set_custom_theme()
# 
# # Chargement du dataset
# @st.cache_data(ttl=3600)
# def load_dataset():
#     try:
#         # Nouveaux IDs des datasets
#         ds1_id = '1ai1QlLzn0uo-enw4IzC53jJ8qoPc845G'  # dataset 1
#         ds2_id = '1MOEhPxMNZH8LvXahvYAKiVFb9t8vAxaE'  # dataset 2
#         ds3_id = '12B-scaR0TF7TuJzelIqmlxXDjnew67-K'  # dataset 3
#         ds4_id = '1U9buLTKR_XuLWu9l3SOgvF6d9cS_YTFO'  # dataset 4
#         ds5_id = '1NdXYppnmiheLFtvrdRHDk-W-zHKO0wYp'  # dataset 5
# 
#         final_id = '1mm6sRacDmoL941POmydQgzdVAi9lFPit'  # Dataset final
# 
#         # Chargement du dataset principal (dataset final)
#         url_final = f'https://drive.google.com/uc?export=download&id={final_id}'
#         df = pd.read_csv(url_final)
# 
# 
#         # Nettoyage et pr√©paration des donn√©es
#         if 'Unnamed: 0' in df.columns:
#             df = df.drop(columns=['Unnamed: 0'])
#         if 'TSA' in df.columns:
#             df['TSA'] = df['TSA'].str.title()
#         elif 'tsa' in df.columns:
#             df.rename(columns={'tsa': 'TSA'}, inplace=True)
#             df['TSA'] = df['TSA'].str.title()
#         if 'Genre' in df.columns:
#             df['Genre'] = df['Genre'].str.capitalize()
#         elif 'gender' in df.columns:
#             df.rename(columns={'gender': 'Genre'}, inplace=True)
#             df['Genre'] = df['Genre'].str.capitalize()
# 
#         # Calcul du score AQ-10
#         aq_columns = [col for col in df.columns if col.startswith('A') and col[1:].isdigit()]
#         if aq_columns:
#             df['Score_A10'] = df[aq_columns].sum(axis=1)
# 
# 
#         if 'Statut_testeur' in df.columns:
#             df['Statut_testeur'].fillna('Famille', inplace=True)
#         else:
#             df['Statut_testeur'] = 'Famille'
# 
# 
#         df_stats = {
#             'mean_by_tsa': df.groupby('TSA').mean(numeric_only=True) if 'TSA' in df.columns else pd.DataFrame(),
#             'count_by_tsa': df.groupby('TSA').count() if 'TSA' in df.columns else pd.DataFrame(),
#             'categorical_cols': df.select_dtypes(include=['object']).columns.tolist(),
#             'numeric_cols': df.select_dtypes(exclude=['object']).columns.tolist()
#         }
# 
#         # Chargement des datasets individuels
#         url_ds1 = f'https://drive.google.com/uc?export=download&id={ds1_id}'
#         url_ds2 = f'https://drive.google.com/uc?export=download&id={ds2_id}'
#         url_ds3 = f'https://drive.google.com/uc?export=download&id={ds3_id}'
#         url_ds4 = f'https://drive.google.com/uc?export=download&id={ds4_id}'
#         url_ds5 = f'https://drive.google.com/uc?export=download&id={ds5_id}'
# 
#         df_ds1 = pd.read_csv(url_ds1)
#         df_ds2 = pd.read_csv(url_ds2)
#         df_ds3 = pd.read_csv(url_ds3)
#         df_ds4 = pd.read_csv(url_ds4)
#         df_ds5 = pd.read_csv(url_ds5)
# 
#         return df, df_ds1, df_ds2, df_ds3, df_ds4, df_ds5, df_stats
#     except Exception as e:
#         st.error(f"Erreur lors du chargement: {str(e)}")
# 
#         return pd.DataFrame(), pd.DataFrame(), pd.DataFrame(), pd.DataFrame(), pd.DataFrame(), pd.DataFrame(), {}
# 
# 
# # Fonction de cache pour les visualisations
# @st.cache_data
# def create_plotly_figure(df, x=None, y=None, color=None, names=None, kind='histogram', title=None):
#     """Cr√©e une visualisation Plotly avec mise en cache"""
# 
#     if color and color not in df.columns:
#         color = None
# 
# 
#     is_categorical_aq = x and isinstance(x, str) and x.startswith('A') and x[1:].isdigit() and len(x) <= 3
# 
#     categorical_palette = {0: "#3498db", 1: "#2ecc71"}
# 
#     try:
#         if is_categorical_aq and kind in ['histogram', 'bar']:
# 
#             counts = df[x].value_counts().reset_index()
#             counts.columns = [x, 'count']
#             fig = px.bar(counts, x=x, y='count',
#                       color=x,
#                       color_discrete_map=categorical_palette,
#                       title=f"Distribution de {x} (cat√©gorielle)")
#             fig.update_layout(xaxis_title=f"Valeur de {x}", yaxis_title="Nombre d'occurrences")
#         elif kind == 'histogram':
#             fig = px.histogram(df, x=x, color=color, color_discrete_map=palette,
#                             marginal="box", nbins=20)
#         elif kind == 'box':
#             fig = px.box(df, x=x, y=y, color=color, color_discrete_map=palette,
#                        points="all", notched=True)
#         elif kind == 'bar':
#             fig = px.bar(df, x=x, y=y, color=color, color_discrete_map=palette)
#         elif kind == 'scatter':
#             fig = px.scatter(df, x=x, y=y, color=color, color_discrete_map=palette)
#         elif kind == 'pie':
# 
#             if names and isinstance(names, str) and names.startswith('A') and names[1:].isdigit() and len(names) <= 3:
# 
#                 values_counts = df[names].value_counts().reset_index()
#                 values_counts.columns = [names, 'count']
#                 fig = px.pie(values_counts, values='count', names=names,
#                           color=names,
#                           color_discrete_map=categorical_palette,
#                           title=f"R√©partition {names}")
#             else:
#                 fig = px.pie(df, names=names, color=color, color_discrete_map=palette)
#         elif kind == 'violin':
#             fig = px.violin(df, x=x, y=y, color=color, color_discrete_map=palette, box=True)
#         elif kind == 'count':
# 
#             fig = px.histogram(df, x=x, color=color, color_discrete_map=palette,
#                             title=f"Comptage de {x}")
#             fig.update_layout(yaxis_title="Nombre d'occurrences")
# 
#         fig.update_layout(
#             title=title,
#             height=500,
#             margin=dict(l=20, r=20, t=40, b=20),
#             template="simple_white"
#         )
# 
#         return fig
#     except Exception as e:
#         st.error(f"Erreur lors de la cr√©ation du graphique: {str(e)}")
#         return None
# 
# 
# if 'df' not in st.session_state:
#     st.session_state.df, st.session_state.df_ds1, st.session_state.df_ds2, st.session_state.df_ds3, st.session_state.df_ds4, st.session_state.df_ds5, st.session_state.df_stats = load_dataset()
# 
# df = st.session_state.df
# df_ds1 = st.session_state.df_ds1
# df_ds2 = st.session_state.df_ds2
# df_ds3 = st.session_state.df_ds3
# df_ds4 = st.session_state.df_ds4
# df_ds5 = st.session_state.df_ds5
# df_stats = st.session_state.df_stats
# 
# 
# if "aq10_total" not in st.session_state:
#     st.session_state.aq10_total = 0
# 
# # Titre de la sidebar am√©lior√©
# st.sidebar.markdown('<p class="sidebar-title">üß© Autisme - Navigation</p>', unsafe_allow_html=True)
# 
# with st.sidebar:
# 
#   # Navigation avec emojis
#     pages = [
#         "üè† Accueil",
#         "üîç Exploration des Donn√©es",
#         "üß† Analyse ML",
#         "üìù Test AQ-10",
#         "ü§ñ Pr√©diction par IA",
#         "üìö Documentation",
#         "‚ÑπÔ∏è √Ä propos"
#     ]
#     selection = st.sidebar.radio("Choisissez un outil :", pages)
# 
# # Palette de couleurs coh√©rente pour toutes les visualisations
# palette = {
#     "Yes": "#3498db",
#     "No": "#2ecc71",
#     "Unknown": "#95a5a6"
# }
# 
# if "üè† Accueil" in selection:
#     current_page = "Accueil"
#     # En-t√™te principal avec image cliquable
#     st.markdown("""
#     <div class="header-container" style="margin-bottom: 30px;">
#         <h1 class="app-title">D√©pistage et Pr√©diction de l'Autisme</h1>
#     </div>
#     """, unsafe_allow_html=True)
# 
#     # Image d'accueil
#     image_url = "https://drive.google.com/file/d/1fY4J-WgufGTF6AgorFOspVKkHiRKEaiW/view?usp=drive_link"
#     st.markdown(get_img_with_href(image_url, "#", as_banner=True), unsafe_allow_html=True)
# 
#     # Section Pr√©sentation
#     st.markdown("""
#     ## Pr√©sentation de la plateforme
#     <div style="background: linear-gradient(90deg, #3498db, #2ecc71); border-radius: 10px; padding: 15px; margin: 20px 0;">
#         <h2 style="color: white; margin: 0; text-align: center;">Notre plateforme de d√©pistage innovante</h2>
#         <h3 style="font-size:1.2rem; font-weight:normal; color:white; margin-top:5px; font-style:italic; text-align: center;">
#             Combiner l'intelligence artificielle et les connaissances cliniques pour un meilleur d√©pistage des Troubles du Spectre Autistique.
#         </h3>
#     </div>
#     """, unsafe_allow_html=True)
# 
#     # Cartes d'acc√®s rapide
#     st.markdown("## Acc√®s rapide aux outils")
#     col1, col2, col3 = st.columns(3, gap="large")
# 
#     with col1:
#         st.markdown("""
#         <div class="info-card fade-in" style="height: 320px; display: flex; flex-direction: column; justify-content: space-between; border-radius: 15px; box-shadow: 0 6px 16px rgba(0, 0, 0, 0.1);">
#             <div>
#                 <h3 class="card-title">üìù Test AQ-10</h3>
#                 <p style="font-size: 1.05rem; margin-bottom: 15px;">Questionnaire standardis√© reconnu internationalement pour le d√©pistage des troubles du spectre autistique.</p>
#                 <p style="color: #2c3e50; font-weight: 500;">Simple, rapide et valid√© scientifiquement.</p>
#             </div>
#             <div style="margin-top: auto; text-align: center; padding-bottom: 15px;">
#                 <a href="?selection=üìù Test AQ-10" class="cta-button" style="display: block; margin: 0 auto;">Commencer le test</a>
#             </div>
#         </div>
#         """, unsafe_allow_html=True)
# 
#     with col2:
#         st.markdown("""
#         <div class="info-card fade-in" style="height: 320px; display: flex; flex-direction: column; justify-content: space-between; border-radius: 15px; box-shadow: 0 6px 16px rgba(0, 0, 0, 0.1);">
#             <div>
#                 <h3 class="card-title">ü§ñ Pr√©diction IA</h3>
#                 <p style="font-size: 1.05rem; margin-bottom: 15px;">Notre mod√®le d'intelligence artificielle analyse vos r√©ponses et d'autres facteurs pour une √©valuation personnalis√©e.</p>
#                 <p style="color: #2c3e50; font-weight: 500;">Pr√©cision √©lev√©e bas√©e sur des milliers de cas cliniques.</p>
#             </div>
#             <div style="margin-top: auto; text-align: center; padding-bottom: 15px;">
#                 <a href="?selection=ü§ñ Pr√©diction par IA" class="cta-button" style="display: block; margin: 0 auto;">D√©couvrir l'IA</a>
#             </div>
#         </div>
#         """, unsafe_allow_html=True)
# 
#     with col3:
#         st.markdown("""
#         <div class="info-card fade-in" style="height: 320px; display: flex; flex-direction: column; justify-content: space-between; border-radius: 15px; box-shadow: 0 6px 16px rgba(0, 0, 0, 0.1);">
#             <div>
#                 <h3 class="card-title">üîç Analyses</h3>
#                 <p style="font-size: 1.05rem; margin-bottom: 15px;">Explorez nos donn√©es, visualisations et insights sur les Troubles du Spectre Autistique (TSA).</p>
#                 <p style="color: #2c3e50; font-weight: 500;">Comprendre les corr√©lations et facteurs importants.</p>
#             </div>
#             <div style="margin-top: auto; text-align: center; padding-bottom: 15px;">
#                 <a href="?selection=üîç Exploration des Donn√©es" class="cta-button" style="display: block; margin: 0 auto;">Explorer les donn√©es</a>
#             </div>
#         </div>
#         """, unsafe_allow_html=True)
# 
#     # Avertissement
#     st.markdown("""
#     ---
#     ### ‚ö†Ô∏è Avertissement
#     <div style="background-color: rgba(52, 152, 219, 0.1); border-left: 4px solid #3498db; padding: 15px; border-radius: 5px; margin: 30px 0;">
#         <strong style="color: #3498db; font-size: 1.1rem;">Important :</strong>
#         <p style="margin-top: 5px;">Cet outil est con√ßu comme aide au d√©pistage et ne remplace en aucun cas une consultation m√©dicale professionnelle.
#         Consultez toujours un sp√©cialiste pour une √©valuation compl√®te.</p>
#     </div>
#     """, unsafe_allow_html=True)
# 
#     # Contexte du projet
#     st.markdown("""
#     ---
#     ## Contexte du projet
#     <p style="font-size: 1.05rem; line-height: 1.6;">
#     Ce projet s'inscrit dans le cadre de l'analyse des donn√©es li√©es au diagnostic des Troubles du Spectre de l'Autisme (TSA), repr√©sentant un ensemble de troubles neurod√©veloppementaux qui apparaissent g√©n√©ralement durant la petite enfance et persistent tout au long de la vie.
#     </p>
#     """, unsafe_allow_html=True)
# 
#     # √Ä qui s'adresse ce projet ?
#     st.markdown("""
#     ---
#     ## √Ä qui s'adresse ce projet ?
#     <div style="background-color: white; padding: 20px; border-radius: 10px; box-shadow: 0 3px 10px rgba(0,0,0,0.08);">
#         <ul style="font-size: 1.05rem; line-height: 1.6;">
#             <li><strong>Personnes concern√©es par les TSA</strong> : Personnes autistes ou suspectant de l'√™tre, souhaitant mieux comprendre ce trouble et r√©aliser un premier d√©pistage.</li>
#             <li><strong>Familles et proches</strong> : Parents, membres de la famille ou amis qui cherchent √† mieux comprendre les TSA et √† identifier d'√©ventuels signes.</li>
#             <li><strong>Professionnels de sant√©</strong> : M√©decins, psychologues, th√©rapeutes qui souhaitent utiliser un outil d'aide au d√©pistage.</li>
#             <li><strong>Chercheurs et √©tudiants</strong> : Personnes int√©ress√©es par l'analyse de donn√©es sur l'autisme et les outils de d√©pistage.</li>
#         </ul>
#     </div>
#     """, unsafe_allow_html=True)
# 
#     # Cat√©gories diagnostiques et niveaux de s√©v√©rit√©
#     st.markdown("""
#     ---
#     ## Crit√®res et niveaux de s√©v√©rit√©
#     """)
#     col1, col2 = st.columns(2)
#     with col1:
#         st.markdown("""
#         <div style="background-color: white; padding: 20px; border-radius: 10px; box-shadow: 0 3px 10px rgba(0,0,0,0.08);">
#             <h4 style="color: #3498db; margin-top: 0;"><span style="font-size: 1.2rem;">üó£Ô∏è</span> D√©ficits de communication</h4>
#             <p>D√©ficits persistants de la communication et des interactions sociales observ√©s dans des contextes vari√©s (difficult√©s dans la r√©ciprocit√© √©motionnelle, les comportements non verbaux et le d√©veloppement des relations)</p>
#         </div>
#         """, unsafe_allow_html=True)
#     with col2:
#         st.markdown("""
#         <div style="background-color: white; padding: 20px; border-radius: 10px; box-shadow: 0 3px 10px rgba(0,0,0,0.08);">
#             <h4 style="color: #3498db; margin-top: 0;"><span style="font-size: 1.2rem;">üîÑ</span> Comportements restreints et r√©p√©titifs</h4>
#             <p>Caract√®re restreint et r√©p√©titif des comportements, des int√©r√™ts ou des activit√©s (mouvements st√©r√©otyp√©s, attachement aux routines, int√©r√™ts restreints et particularit√©s sensorielles)</p>
#         </div>
#         """, unsafe_allow_html=True)
# 
#     st.markdown("""
#     <p style="font-size: 1.05rem; line-height: 1.6; margin-top: 20px;">
#     Les classifications actuelles ont abandonn√© les sous-types d'autisme (comme le syndrome d'Asperger ou l'autisme de Kanner)
#     au profit d'un diagnostic unique de TSA avec trois niveaux de s√©v√©rit√© refl√©tant le degr√© de soutien n√©cessaire:
#     </p>
#     """, unsafe_allow_html=True)
# 
#     col1, col2, col3 = st.columns(3)
#     with col1:
#         st.markdown("""
#         <div style="background-color: #e8f5e9; padding: 15px; border-radius: 10px; border-left: 4px solid #2ecc71;">
#             <h4 style="color: #2ecc71; margin-top: 0;">Niveau 1</h4>
#             <p>N√©cessite un soutien</p>
#         </div>
#         """, unsafe_allow_html=True)
#     with col2:
#         st.markdown("""
#         <div style="background-color: #eaf2f8; padding: 15px; border-radius: 10px; border-left: 4px solid #3498db;">
#             <h4 style="color: #3498db; margin-top: 0;">Niveau 2</h4>
#             <p>N√©cessite un soutien important</p>
#         </div>
#         """, unsafe_allow_html=True)
#     with col3:
#         st.markdown("""
#         <div style="background-color: #f5eef8; padding: 15px; border-radius: 10px; border-left: 4px solid #9b59b6;">
#             <h4 style="color: #9b59b6; margin-top: 0;">Niveau 3</h4>
#             <p>N√©cessite un soutien tr√®s important</p>
#         </div>
#         """, unsafe_allow_html=True)
# 
#     # Pr√©valence
#     st.markdown("""
#     ---
#     ## Pr√©valence
#     <div style="background-color: white; padding: 20px; border-radius: 10px; box-shadow: 0 3px 10px rgba(0,0,0,0.08); margin-top: 20px;">
#         <h4 style="color: #3498db; margin-top: 0;"><span style="font-size: 1.2rem;">üìä</span> Pr√©valence</h4>
#         <p style="font-size: 1.05rem; line-height: 1.6;">
#         La pr√©valence des TSA est estim√©e √† environ 1% de la population mondiale...
#         </p>
#     </div>
#     """, unsafe_allow_html=True)
# 
# 
# elif "üîç Exploration des Donn√©es" in selection:
#     # Initialisation des √©tats d'expanders
#     if 'expanders_initialized' not in st.session_state:
#         st.session_state.expanders_initialized = {
#             'structure': True,
#             'valeurs_manquantes': True,
#             'pipeline': True,
#             'variables_cles': True,
#             'questionnaire': True,
#             'composite': True,
#             'statistiques': True,
#             'correlation': True,
#             'famd': True
#         }
# 
#     # En-t√™te modernis√©
#     st.markdown("""
#     <div class="header-container">
#         <span style="font-size:2.5rem">üîç</span>
#         <h1 class="app-title">Exploration des Donn√©es TSA</h1>
#     </div>
#     """, unsafe_allow_html=True)
# 
#     # 1. Structure des donn√©es
#     with st.expander("üìÇ Structure des Donn√©es", expanded=st.session_state.expanders_initialized['structure']):
#         st.markdown("""
#         <div style="background-color: #f0f7ff; padding: 15px; border-radius: 8px; margin-top: 15px; border-left: 4px solid #3498db;">
#             <h4 style="color: #2c3e50; margin-top: 0;">Description des jeux de donn√©es utilis√©s</h4>
#             <ul style="margin-top: 10px;">
#                 <li><strong>Dataset Final :</strong> 5049 sujets consolid√©s</li>
#                 <li><strong>Variables :</strong> 21 variables dont 10 questions AQ-10</li>
#                 <li><strong>P√©riode :</strong> Donn√©es collect√©es entre 2018 et 2023</li>
#             </ul>
#         </div>
#         """, unsafe_allow_html=True)
#         tab_main, tab1, tab2, tab3, tab4, tab5 = st.tabs([
#             "Dataset Final", "Dataset 1", "Dataset 2", "Dataset 3", "Dataset 4", "Dataset 5"
#         ])
#         with tab_main:
#             st.caption("Dataset Final")
#             st.dataframe(df.head(5), use_container_width=True)
#         with tab1:
#             st.caption("Dataset 1")
#             st.dataframe(df_ds1.head(5), use_container_width=True)
#         with tab2:
#             st.caption("Dataset 2")
#             st.dataframe(df_ds2.head(5), use_container_width=True)
#         with tab3:
#             st.caption("Dataset 3")
#             st.dataframe(df_ds3.head(5), use_container_width=True)
#         with tab4:
#             st.caption("Dataset 4")
#             st.dataframe(df_ds4.head(5), use_container_width=True)
#         with tab5:
#             st.caption("Dataset 5")
#             st.dataframe(df_ds5.head(5), use_container_width=True)
# 
#     # 2. Analyse des valeurs manquantes
#     with st.expander("üìâ Analyse des Valeurs Manquantes", expanded=st.session_state.expanders_initialized['valeurs_manquantes']):
#         st.markdown("""
#         <div style="background-color: #f8f9fa; padding: 15px; border-radius: 8px; margin-bottom: 20px;">
#             <h3 style="color: #2c3e50; margin-top: 0;">Analyse des Valeurs Manquantes</h3>
#             <p style="color: #7f8c8d;">Visualisation et quantification des donn√©es manquantes dans le jeu de donn√©es.</p>
#         </div>
#         """, unsafe_allow_html=True)
#         missing_percent = (df.isnull().sum() / len(df)) * 100
#         missing_info = pd.DataFrame({
#             'Colonne': missing_percent.index,
#             'Pourcentage': missing_percent.values
#         })
#         missing_info = missing_info[missing_info['Pourcentage'] > 0].sort_values('Pourcentage', ascending=False)
#         if not missing_info.empty:
#             col1, col2 = st.columns([3, 2])
#             with col1:
#                 fig = px.bar(
#                     missing_info,
#                     x='Pourcentage',
#                     y='Colonne',
#                     orientation='h',
#                     title="Pourcentage de valeurs manquantes par colonne",
#                     color='Pourcentage',
#                     color_continuous_scale=px.colors.sequential.Blues,
#                     text='Pourcentage'
#                 )
#                 fig.update_traces(texttemplate='%{text:.2f}%', textposition='outside')
#                 fig.update_layout(
#                     height=400,
#                     xaxis_title="Pourcentage (%)",
#                     yaxis_title="",
#                     coloraxis_showscale=False,
#                     margin=dict(l=20, r=20, t=40, b=20),
#                 )
#                 st.plotly_chart(fig, use_container_width=True)
#             with col2:
#                 st.metric(
#                     "Nombre de colonnes avec valeurs manquantes",
#                     missing_info.shape[0],
#                     delta=f"{missing_info.shape[0]/df.shape[1]:.1%} des colonnes"
#                 )
#                 st.markdown("### D√©tail des valeurs manquantes")
#                 st.dataframe(missing_info, use_container_width=True)
#                 total_missing = (df.isnull().sum().sum() / (df.shape[0] * df.shape[1])) * 100
#                 st.info(f"Taux global de donn√©es manquantes : {total_missing:.2f}%")
#         else:
#             st.success("‚úÖ Aucune valeur manquante d√©tect√©e dans le jeu de donn√©es.")
# 
#     # 3. Pipeline de nettoyage
#     with st.expander("üßº Pipeline de Nettoyage", expanded=st.session_state.expanders_initialized['pipeline']):
#         st.markdown("""
#         <div style="background-color: #f8f9fa; padding: 15px; border-radius: 8px; margin-bottom: 20px;">
#             <h3 style="color: #2c3e50; margin-top: 0;">√âtapes de Transformation des Donn√©es</h3>
#             <p style="color: #7f8c8d;">Processus automatis√© pour pr√©parer les donn√©es √† l'analyse.</p>
#         </div>
#         """, unsafe_allow_html=True)
#         col1, col2 = st.columns([1, 3])
#         with col1:
#             st.markdown("""
#             <div style="background-color: white; padding: 15px; border-radius: 8px; box-shadow: 0 2px 5px rgba(0,0,0,0.05);">
#                 <h4 style="color: #3498db; margin-top: 0;">√âtapes de Transformation</h4>
#                 <ol style="padding-left: 20px; color: #2c3e50;">
#                     <li><b>Uniformisation</b> des colonnes</li>
#                     <li><b>Typage</b> des variables</li>
#                     <li><b>Gestion</b> des valeurs manquantes</li>
#                     <li><b>Encodage</b> cat√©goriel</li>
#                     <li><b>Normalisation</b> des √©chelles</li>
#                 </ol>
#             </div>
#             """, unsafe_allow_html=True)
#         with col2:
#             avant_tab, apres_tab = st.tabs(["Avant Nettoyage", "Apr√®s Nettoyage"])
#             with avant_tab:
#                 raw_data_sample = pd.DataFrame({
#                     'A10_Score': [7, 5, None, 3],
#                     'Age_Years': [29, None, 'unknown', 383],
#                     'asd_traits': ['yes', 'no', 'no', 'yes']
#                 })
#                 st.dataframe(raw_data_sample.style.highlight_null(color='#ffcdd2'), use_container_width=True)
#             with apres_tab:
#                 clean_data_sample = pd.DataFrame({
#                     'A10': [7, 5, 4, 3],
#                     'Age': [29, 35, 42, 38],
#                     'TSA': ['Yes', 'No', 'No', 'Yes'],
#                     'Statut_testeur': ['Famille', 'Famille', 'Famille', 'Famille']
#                 })
#                 st.dataframe(clean_data_sample, use_container_width=True)
#                 metrics_col1, metrics_col2 = st.columns(2)
#                 with metrics_col1:
#                     st.metric("R√©duction des valeurs manquantes", "92%", "10% ‚Üí 0.8%")
#                 with metrics_col2:
#                     st.metric("Anomalies corrig√©es", "100%", "14 anomalies d√©tect√©es")
# 
#     # 4. Distribution des variables cl√©s
#     with st.expander("üìä Distribution des Variables Cl√©s", expanded=st.session_state.expanders_initialized['variables_cles']):
#         st.markdown("""
#         <div style="background-color: #f8f9fa; padding: 15px; border-radius: 8px; margin-bottom: 20px;">
#             <h3 style="color: #2c3e50; margin-top: 0;">Distribution des Variables Cl√©s</h3>
#             <p style="color: #7f8c8d;">Analyse interactive des distributions par variable et diagnostic TSA.</p>
#         </div>
#         """, unsafe_allow_html=True)
#         all_columns = [col for col in df.columns if col != 'TSA']
#         analysis_var = st.selectbox("Choisir une variable √† analyser", all_columns, key="analysis_var_in_exploration")
#         col1, col2 = st.columns(2)
#         with col1:
#             color_var = 'TSA' if 'TSA' in df.columns else None
#             # Correction sp√©cifique pour la variable Jaunisse (cat√©gorielle)
#             if analysis_var == 'Jaunisse':
#                 fig = px.histogram(df, x='Jaunisse', color='TSA',
#                                    color_discrete_map=palette,
#                                    barnorm='percent',
#                                    title="Pr√©valence de la jaunisse par statut TSA")
#                 st.plotly_chart(fig, use_container_width=True)
#             else:
#                 is_categorical_aq = analysis_var.startswith('A') and analysis_var[1:].isdigit() and len(analysis_var) <= 3
#                 if is_categorical_aq:
#                     fig = create_plotly_figure(df, x=analysis_var, color=color_var, kind='bar', title=f"Distribution de {analysis_var} (cat√©gorielle)")
#                 else:
#                     fig = create_plotly_figure(df, x=analysis_var, color=color_var, kind='histogram', title=f"Distribution de {analysis_var}")
#                 if fig:
#                     st.plotly_chart(fig, use_container_width=True)
#         with col2:
#             if 'TSA' in df.columns:
#                 stats = df.groupby('TSA')[analysis_var].describe()
#             else:
#                 stats = df[analysis_var].describe().to_frame().T
#             st.dataframe(stats, use_container_width=True)
# 
#     # 5. Analyse des r√©ponses au questionnaire A10
#     with st.expander("üìù Analyse des R√©ponses au Questionnaire AQ-10", expanded=st.session_state.expanders_initialized['questionnaire']):
#         st.subheader("Analyse des R√©ponses au Questionnaire AQ-10")
#         question_tabs = st.tabs([f"Q{i+1}" for i in range(10)])
#         for i, tab in enumerate(question_tabs):
#             with tab:
#                 col1, col2 = st.columns([2,3])
#                 with col1:
#                     st.write(f"**Question A{i+1} :**")
#                     st.markdown("> " + get_question_text(i+1))
#                 with col2:
#                     try:
#                         values_counts = df[f'A{i+1}'].value_counts().reset_index()
#                         values_counts.columns = [f'A{i+1}', 'count']
#                         color_discrete_map = {0: "#2ecc71", 1: "#3498db"}
#                         fig = px.pie(
#                             values_counts,
#                             values='count',
#                             names=f'A{i+1}',
#                             color=f'A{i+1}',
#                             color_discrete_map=color_discrete_map,
#                             title=f"R√©partition des r√©ponses A{i+1}"
#                         )
#                         st.plotly_chart(fig, use_container_width=True)
#                     except Exception as e:
#                         st.error(f"Erreur lors de la cr√©ation du graphique: {str(e)}")
# 
#     # 6. Cr√©ation de variable composite
#     with st.expander("‚öôÔ∏è Cr√©ation de Variables Composites", expanded=st.session_state.expanders_initialized['composite']):
#         st.subheader("Cr√©ation de Variables Composites")
#         col1, col2 = st.columns(2)
#         with col1:
#             st.write("**Score A10 :**")
#             st.markdown("""
#             $$
#             \\text{Score\\_A10} = \\sum_{i=1}^{10} A_i
#             $$
#             """)
#             if 'TSA' in df.columns:
#                 yes_mean = df[df['TSA'] == 'Yes']['Score_A10'].mean()
#                 no_mean = df[df['TSA'] == 'No']['Score_A10'].mean()
#                 st.metric("Score Moyen (TSA)", f"{yes_mean:.1f} ¬± {df[df['TSA'] == 'Yes']['Score_A10'].std():.1f}")
#                 st.metric("Score Moyen (Non-TSA)", f"{no_mean:.1f} ¬± {df[df['TSA'] == 'No']['Score_A10'].std():.1f}")
#             else:
#                 overall_mean = df['Score_A10'].mean()
#                 st.metric("Score Moyen", f"{overall_mean:.1f} ¬± {df['Score_A10'].std():.1f}")
#         with col2:
#             color_var = 'TSA' if 'TSA' in df.columns else None
#             fig = create_plotly_figure(df, y='Score_A10', color=color_var, kind='violin', title="Distribution des Scores")
#             if fig:
#                 st.plotly_chart(fig, use_container_width=True)
# 
#     # 7. Statistiques du dataset final
#     with st.expander("üìà Statistiques du Dataset Final", expanded=st.session_state.expanders_initialized['statistiques']):
#         st.subheader("Statistiques Descriptives")
#         tab1, tab2 = st.tabs(["Num√©riques", "Cat√©gorielles"])
#         with tab1:
#             st.write(df.describe())
#         with tab2:
#             categorical_stats = df.select_dtypes(include=['object']).describe().T
#             st.dataframe(categorical_stats)
# 
#     # 8. Matrice de corr√©lation
#     with st.expander("üîó Matrice de Corr√©lation", expanded=st.session_state.expanders_initialized['correlation']):
#         try:
#             df_corr = df.copy()
#             if 'Jaunisse' in df_corr.columns:
#                 df_corr = df_corr.drop(columns=['Jaunisse'])
#             if 'TSA' in df_corr.columns:
#                 df_corr['TSA_num'] = df_corr['TSA'].map({'Yes': 1, 'No': 0})
#             categorical_cols = df_corr.select_dtypes(include=['object']).columns
#             if not categorical_cols.empty:
#                 ohe = OneHotEncoder(sparse_output=False, drop='first')
#                 encoded_data = ohe.fit_transform(df_corr[categorical_cols])
#                 feature_names = ohe.get_feature_names_out(categorical_cols)
#                 encoded_df = pd.DataFrame(encoded_data, columns=feature_names)
#                 numeric_df = df_corr.select_dtypes(exclude=['object']).reset_index(drop=True)
#                 df_corr_processed = pd.concat([numeric_df, encoded_df], axis=1)
#             else:
#                 df_corr_processed = df_corr.select_dtypes(exclude=['object'])
#             corr_matrix = df_corr_processed.corr(numeric_only=True)
#             mask = np.triu(np.ones_like(corr_matrix, dtype=bool))
#             fig, ax = plt.subplots(figsize=(14, 12))
#             cmap = sns.diverging_palette(200, 120, as_cmap=True)
#             sns.heatmap(
#                 corr_matrix,
#                 mask=mask,
#                 cmap=cmap,
#                 vmax=1.0,
#                 vmin=-1.0,
#                 center=0,
#                 square=True,
#                 linewidths=0.8,
#                 fmt='.2f',
#                 annot=True,
#                 annot_kws={"size": 9, "weight": "bold"},
#                 cbar_kws={"shrink": 0.8, "label": "Coefficient de corr√©lation"}
#             )
#             plt.title("Matrice de corr√©lation des variables", fontsize=16, pad=20)
#             plt.xticks(rotation=45, ha='right', fontsize=9)
#             plt.yticks(fontsize=9)
#             plt.tight_layout()
#             st.pyplot(fig)
#         except Exception as e:
#             st.error(f"Erreur lors du calcul de la matrice de corr√©lation: {str(e)}")
# 
#     # 9. Tests statistiques (menu d√©roulant s√©par√©)
#     with st.expander("üß™ Tests Statistiques", expanded=True):
#         test_type = st.radio(
#             "Choisir le type de test:",
#             ["Chi-carr√© (variables cat√©gorielles)", "Mann-Whitney (variables num√©riques)"],
#             key="stat_test_type"
#         )
#         if test_type == "Chi-carr√© (variables cat√©gorielles)":
#                 st.markdown("""
#                 <div style="background-color: #f0f7ff; padding: 15px; border-radius: 8px; margin-bottom: 20px;">
#                     <h4 style="color: #3498db; margin-top: 0;">Test d'ind√©pendance du Chi-carr√©</h4>
#                     <p>Ce test √©value si deux variables cat√©gorielles sont ind√©pendantes. Un p-value < 0.05 sugg√®re une relation significative entre les variables.</p>
#                 </div>
#                 """, unsafe_allow_html=True)
# 
#                 # D√©finir categorical_cols
#                 df = df.copy()
#                 categorical_cols = df.select_dtypes(include=['object']).columns.tolist()
# 
#                 # Ajouter les variables A1-A10 aux variables cat√©gorielles
#                 aq_columns = [col for col in df.columns if col.startswith('A') and col[1:].isdigit()]
#                 categorical_cols.extend([col for col in aq_columns if col not in categorical_cols])
# 
#                 if 'TSA' in categorical_cols:
#                     categorical_cols.remove('TSA')
# 
#                 # S√©lection de la variable cat√©gorielle √† tester
#                 if categorical_cols:
#                     cat_var = st.selectbox(
#                         "S√©lectionner une variable cat√©gorielle:",
#                         categorical_cols,
#                         key="chi2_var_selector"
#                     )
# 
#                     # R√©alisation du test
#                     try:
#                         # Cr√©ation d'une table de contingence
#                         contingency_table = pd.crosstab(df[cat_var], df['TSA'])
# 
#                         # Calcul du chi2
#                         chi2_stat, p_val, dof, expected = chi2_contingency(contingency_table)
# 
#                         # Affichage des r√©sultats
#                         col1, col2 = st.columns(2)
#                         with col1:
#                             st.markdown("### Table de contingence")
#                             st.dataframe(contingency_table.style.set_properties(**{'background-color': 'white'}), use_container_width=True)
#                             # Afficher les fr√©quences relatives (%)
#                             st.markdown("### Fr√©quences relatives (%)")
#                             contingency_percent = contingency_table.div(contingency_table.sum(axis=1), axis=0) * 100
#                             st.dataframe(
#                                 contingency_percent.style.format("{:.1f}%"),
#                                 use_container_width=True
#                             )
# 
#                         with col2:
#                             st.markdown("### R√©sultats du test")
#                             st.metric("Statistique œá¬≤", f"{chi2_stat:.3f}")
#                             st.metric("p-value", f"{p_val:.5f}")
#                             st.metric("Degr√©s de libert√©", dof)
# 
#                             # Interpr√©tation
#                             if p_val < 0.05:
#                                 st.success(f"**Significatif** (p < 0.05) : Il existe une relation significative entre '{cat_var}' et le diagnostic TSA.")
#                             else:
#                                 st.info(f"**Non significatif** (p > 0.05) : Pas de relation significative d√©tect√©e entre '{cat_var}' et le diagnostic TSA.")
# 
#                         # Visualisation
#                         st.markdown("### Visualisation de la relation")
#                         fig = px.bar(
#                             contingency_percent.reset_index().melt(id_vars=cat_var),
#                             x=cat_var, y='value', color='TSA',
#                             barmode='group',
#                             color_discrete_map=palette,
#                             labels={'value': 'Pourcentage (%)'},
#                             title=f"Distribution de '{cat_var}' par diagnostic TSA"
#                         )
#                         st.plotly_chart(fig, use_container_width=True)
# 
#                     except Exception as e:
#                         st.error(f"Erreur lors du test Chi-carr√©: {str(e)}")
#                         st.info("Assurez-vous que la variable s√©lectionn√©e contient suffisamment de donn√©es non-nulles.")
#                 else:
#                     st.warning("Aucune variable cat√©gorielle trouv√©e dans le dataset (en excluant TSA).")
# 
#         else:  # Mann-Whitney
#             st.markdown("""
#                 <div style="background-color: #f0f7ff; padding: 15px; border-radius: 8px; margin-bottom: 20px;">
#                     <h4 style="color: #3498db; margin-top: 0;">Test de Mann-Whitney U</h4>
#                     <p>Ce test non-param√©trique compare les distributions de deux groupes ind√©pendants. Un p-value < 0.05 sugg√®re une diff√©rence significative entre les groupes.</p>
#                 </div>
#                 """, unsafe_allow_html=True)
# 
# 
#             numeric_cols = df.select_dtypes(include=['float', 'int']).columns.tolist()
#                 # Retirer A1-A10 de l'analyse Mann-Whitney
#             numeric_cols = [col for col in numeric_cols if not (col.startswith('A') and col[1:].isdigit() and len(col) <= 3)]
# 
#             if 'Score_A10' in numeric_cols:
#                     # Mettre Score_A10 en t√™te de liste car souvent analys√©
#                 numeric_cols.remove('Score_A10')
#                 numeric_cols = ['Score_A10'] + numeric_cols
# 
#             if numeric_cols:
#                 num_var = st.selectbox(
#                     "S√©lectionner une variable num√©rique:",
#                     numeric_cols,
#                     key="mw_var_selector"
#                     )
# 
# 
#                     # R√©alisation du test
#                 try:
#                     if 'TSA' in df.columns and df['TSA'].nunique() >= 2:
#                             # Pr√©paration des groupes
#                         yes_group = df[df['TSA'] == 'Yes'][num_var].dropna()
#                         no_group = df[df['TSA'] == 'No'][num_var].dropna()
# 
#                         if len(yes_group) > 0 and len(no_group) > 0:
#                                 # R√©alisation du test Mann-Whitney
#                             stat, p_val = mannwhitneyu(yes_group, no_group, alternative='two-sided')
# 
#                                 # Affichage des r√©sultats
#                             col1, col2 = st.columns(2)
#                             with col1:
#                                 st.markdown("### Statistiques descriptives")
#                                 group_stats = df.groupby('TSA')[num_var].agg(['count', 'mean', 'std', 'min', 'median', 'max'])
#                                 st.dataframe(
#                                     group_stats.style.format("{:.2f}", subset=['mean', 'std', 'min', 'median', 'max']),
#                                     use_container_width=True
#                                     )
# 
#                                     # Diff√©rence des moyennes
#                                 mean_diff = yes_group.mean() - no_group.mean()
#                                 st.metric(
#                                         "Diff√©rence des moyennes (TSA - Non TSA)",
#                                     f"{mean_diff:.2f}",
#                                     delta=f"{(mean_diff / no_group.mean()) * 100:.1f}%"
#                                     )
# 
#                             with col2:
#                                 st.markdown("### R√©sultats du test")
#                                 st.metric("Statistique U", f"{stat:.1f}")
#                                 st.metric("p-value", f"{p_val:.5f}")
#                                     # Taille de l'√©chantillon
#                                 st.metric("Taille √©chantillon (TSA / Non TSA)", f"{len(yes_group)} / {len(no_group)}")
# 
#                                     # Interpr√©tation
#                                 if p_val < 0.05:
#                                     st.success(f"**Significatif** (p < 0.05) : Il existe une diff√©rence significative de '{num_var}' entre les groupes TSA et non-TSA.")
#                                 else:
#                                     st.info(f"**Non significatif** (p > 0.05) : Pas de diff√©rence significative de '{num_var}' d√©tect√©e entre les groupes TSA et non-TSA.")
# 
#                                 # Visualisation
#                             st.markdown("### Visualisation de la comparaison")
#                             fig = px.box(
#                                 df.dropna(subset=[num_var]), x='TSA', y=num_var,
#                                 color='TSA', color_discrete_map=palette,
#                                 points='all', notched=True,
#                                 title=f"Comparaison de '{num_var}' entre les groupes TSA et non-TSA"
#                                 )
#                             fig.add_annotation(
#                                 x=0.5, y=df[num_var].max() * 0.95,
#                                 text=f"p-value = {p_val:.5f}" + (" (significatif)" if p_val < 0.05 else ""),
#                                 showarrow=False,
#                                 font=dict(size=14, color='red' if p_val < 0.05 else 'gray')
#                                 )
#                             st.plotly_chart(fig, use_container_width=True)
#                         else:
#                             st.warning(f"Impossible de r√©aliser le test: donn√©es insuffisantes pour '{num_var}' dans un ou les deux groupes.")
#                     else:
#                         st.warning("Pour effectuer ce test, le dataset doit contenir une colonne 'TSA' avec au moins deux groupes distincts.")
#                 except Exception as e:
#                     st.error(f"Erreur lors du test de Mann-Whitney: {str(e)}")
#                     st.info("Assurez-vous que la variable s√©lectionn√©e contient suffisamment de donn√©es num√©riques non-nulles.")
#             else:
#                 st.warning("Aucune variable num√©rique trouv√©e dans le dataset.")
# 
# 
# 
#     with st.expander("üìê Analyse Factorielle (FAMD)", expanded=st.session_state.expanders_initialized['famd']):
#         st.header("Analyse Factorielle Mixte (FAMD)")
#         try:
#             df_famd = df.copy()
#             n_components = 5
#             X_famd = df_famd.copy()
#             famd = prince.FAMD(n_components=n_components, n_iter=10, random_state=42)
#             famd = famd.fit(X_famd)
#             eigenvalues = famd.eigenvalues_
#             explained_variance = eigenvalues / sum(eigenvalues)
# 
#             # Projection des individus
#             st.subheader("Projection des individus (FAMD)")
#             if hasattr(famd, 'row_coordinates'):
#                 coordinates = famd.row_coordinates(X_famd)
#                 fig, ax = plt.subplots(figsize=(10, 8))
#                 if 'TSA' in df_famd.columns:
#                     for category in df_famd['TSA'].unique():
#                         mask = df_famd['TSA'] == category
#                         subset_indices = df_famd[mask].index
#                         ax.scatter(
#                             coordinates.iloc[subset_indices, 0],
#                             coordinates.iloc[subset_indices, 1],
#                             label=category,
#                             alpha=0.7
#                         )
#                     ax.legend()
#                 else:
#                     ax.scatter(coordinates.iloc[:, 0], coordinates.iloc[:, 1], alpha=0.7)
#                 ax.set_xlabel('Composante 1')
#                 ax.set_ylabel('Composante 2')
#                 ax.set_title('Projection des individus sur les deux premi√®res composantes')
#                 ax.grid(True, linestyle='--', alpha=0.7)
#                 st.pyplot(fig)
# 
#             # Cercle des corr√©lations - IMPL√âMENTATION ALTERNATIVE
#             st.subheader("Cercle des corr√©lations (variables actives)")
#             try:
#                 # R√©cup√©ration des coordonn√©es des variables directement de l'objet famd
#                 if hasattr(famd, 'column_coordinates'):
#                     # Utiliser la m√©thode de projection des colonnes pour avoir les coordonn√©es
#                     var_coordinates = famd.column_coordinates(X_famd)
# 
#                     # Cr√©ation du cercle de corr√©lation
#                     fig, ax = plt.subplots(figsize=(8, 8))
# 
#                     # Dessiner le cercle unitaire
#                     circle = plt.Circle((0, 0), 1, color='gray', fill=False, linestyle='--')
#                     ax.add_artist(circle)
# 
#                     # Dessiner des lignes de r√©f√©rence
#                     ax.axhline(y=0, color='gray', linestyle='-', alpha=0.3)
#                     ax.axvline(x=0, color='gray', linestyle='-', alpha=0.3)
# 
#                     # Tracer chaque variable comme un vecteur
#                     for i, var in enumerate(var_coordinates.index):
#                         x = var_coordinates.iloc[i, 0]
#                         y = var_coordinates.iloc[i, 1]
# 
#                         # Normaliser les vecteurs qui d√©passent le cercle unitaire
#                         norm = np.sqrt(x**2 + y**2)
#                         if norm > 1:
#                             x, y = x/norm, y/norm
# 
#                         ax.arrow(0, 0, x, y, head_width=0.05, head_length=0.05, fc='blue', ec='blue', alpha=0.7)
#                         ax.text(x*1.1, y*1.1, var, fontsize=9)
# 
#                     # Configuration de l'aspect du graphique
#                     ax.set_xlim(-1.1, 1.1)
#                     ax.set_ylim(-1.1, 1.1)
#                     ax.set_xlabel(f'Composante 1 ({explained_variance[0]:.2%})')
#                     ax.set_ylabel(f'Composante 2 ({explained_variance[1]:.2%})')
#                     ax.set_title('Cercle des corr√©lations des variables')
#                     ax.grid(True, linestyle='--', alpha=0.5)
# 
#                     # Afficher le graphique
#                     st.pyplot(fig)
#                 else:
#                     st.warning("La m√©thode 'column_coordinates' n'est pas disponible dans cette version de prince.")
# 
#             except Exception as e:
#                 st.error(f"Erreur lors de la cr√©ation du cercle des corr√©lations : {str(e)}")
# 
#                 # Solution alternative : afficher les contributions des variables aux axes
#                 if hasattr(famd, 'column_contributions_'):
#                     st.write("### Contributions des variables aux axes principaux")
#                     contrib = famd.column_contributions_
#                     st.dataframe(contrib.head())
#                 else:
#                     st.warning("Impossible d'afficher les contributions des variables.")
# 
#             # Inertie expliqu√©e
#             st.subheader("Importance des composantes")
#             inertia_df = pd.DataFrame({
#                 'Composante': [f'Composante {i+1}' for i in range(len(explained_variance))],
#                 'Inertie expliqu√©e': explained_variance,
#                 'Inertie cumul√©e': np.cumsum(explained_variance)
#             })
#             st.table(inertia_df.head(5))
# 
#             # Commentaires/interpr√©tation
#             st.markdown("""
#             ### Interpr√©tation des r√©sultats FAMD
# 
#             - La **projection des individus** montre une s√©paration partielle mais visible entre les groupes TSA et non-TSA, ce qui confirme que les variables s√©lectionn√©es captent des diff√©rences structurantes dans la population.
#             - Le **cercle des corr√©lations** r√©v√®le que la variable `Score_A10` est fortement corr√©l√©e √† la premi√®re composante, tandis que des variables comme le `Statut_testeur` ou l'`Ethnie` contribuent √©galement √† la structuration des axes, mais de fa√ßon moins marqu√©e.
#             - Ces r√©sultats justifient l'utilisation de mod√®les supervis√©s pour la pr√©diction du diagnostic TSA et confirment la pertinence du score AQ-10 comme variable synth√©tique.
#             """)
#         except Exception as e:
#             st.error(f"Erreur lors de l'analyse FAMD: {str(e)}")
# 
# 
# 
# 
# 
# elif "üß† Analyse ML" in selection:
#     current_page = "Analyse ML"
#     # En-t√™te modernis√©
#     st.markdown("""
#     <div class="header-container">
#         <span style="font-size:2.5rem">üß†</span>
#         <h1 class="app-title">Analyse par Machine Learning</h1>
#     </div>
#     """, unsafe_allow_html=True)
# 
#     # Mod√©lisation directe sans utiliser FAMD pour transformation
#     st.header("Mod√©lisation par Random Forest")
#     with st.spinner("üå≥ Entra√Ænement du mod√®le..."):
#         try:
#             if 'TSA' not in df.columns:
#                 st.error("La colonne 'TSA' n'est pas pr√©sente dans le DataFrame.")
#                 st.info("Assurez-vous que votre jeu de donn√©es contient bien une colonne 'TSA'.")
#             else:
#                 # Pr√©parer les donn√©es sans utiliser FAMD
#                 # S√©parer les variables num√©riques et cat√©gorielles
#                 categorical_cols = df.select_dtypes(include=['object']).columns.tolist()
#                 if 'TSA' in categorical_cols:
#                     categorical_cols.remove('TSA')
#                 numerical_cols = df.select_dtypes(exclude=['object']).columns.tolist()
# 
#                 # Explication des pipelines de pr√©traitement
#                 st.subheader("Explication d√©taill√©e du pipeline de pr√©traitement")
#                 st.markdown("""
#                 ### Pipeline de pr√©processing pour les donn√©es mixtes
# 
#                 Notre pipeline de pr√©traitement g√®re √† la fois les variables num√©riques et cat√©gorielles de mani√®re appropri√©e:
# 
#                 #### 1. Standardisation des variables num√©riques
#                 ```
#                 ('num', StandardScaler(), numerical_cols)
#                 ```
#                 - Applique une standardisation (moyenne=0, √©cart-type=1) aux variables num√©riques
#                 - Essentiel pour les algorithmes sensibles √† l'√©chelle comme les SVM ou les r√©gressions r√©gularis√©es
#                 - Permet de comparer l'importance des variables malgr√© leurs √©chelles d'origine diff√©rentes
# 
#                 #### 2. Encodage des variables cat√©gorielles
#                 ```
#                 ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)
#                 ```
#                 - Transforme les variables cat√©gorielles en variables binaires (one-hot encoding)
#                 - Param√®tre `handle_unknown='ignore'` g√®re les cat√©gories inconnues (non pr√©sentes lors de l'entra√Ænement)
#                 - Cr√©e une colonne distincte pour chaque modalit√©, sauf une pour √©viter la multicolin√©arit√©
# 
#                 #### 3. Conservation des colonnes non sp√©cifi√©es
#                 ```
#                 remainder='passthrough'
#                 ```
#                 - Conserve les colonnes qui ne sont ni num√©riques ni cat√©gorielles
#                 - Assure qu'aucune information n'est perdue lors du pr√©traitement
# 
#                 #### Avantages de cette approche
#                 - **Reproductibilit√©**: Le m√™me pr√©traitement est appliqu√© √† l'entra√Ænement et √† la pr√©diction
#                 - **√âvitement des fuites de donn√©es**: Les param√®tres de scaling sont calcul√©s uniquement sur l'ensemble d'entra√Ænement
#                 - **Flexibilit√©**: Facilement adaptable √† diff√©rents types de donn√©es et d'algorithmes
#                 """)
# 
#                 # Pr√©processeur pour les donn√©es mixtes avec remainder='passthrough'
#                 # pour conserver toutes les colonnes, y compris Statut_testeur
#                 preprocessor = ColumnTransformer(
#                     transformers=[
#                         ('num', StandardScaler(), numerical_cols),
#                         ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)
#                     ],
#                     remainder='passthrough',  # Conserver les colonnes non sp√©cifi√©es
#                     verbose_feature_names_out=False
#                 )
# 
#                 X = df.drop(columns=['TSA'])
#                 y = df['TSA'].map({'Yes': 1, 'No': 0})
# 
#                 # Pipeline avec pr√©processeur et Random Forest optimis√© pour Google Colab
#                 pipeline = Pipeline([
#                     ('preprocessor', preprocessor),
#                     ('classifier', RandomForestClassifier(
#                         n_estimators=50,  # R√©duit de 100 √† 50 pour acc√©l√©rer
#                         max_depth=8,
#                         min_samples_split=10,
#                         min_samples_leaf=2,
#                         max_features='sqrt',  # Pour acc√©l√©rer
#                         random_state=42,
#                         n_jobs=-1  # Utiliser tous les c≈ìurs disponibles
#                     ))
#                 ])
# 
#                 # Division train/test et entra√Ænement
#                 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
#                 pipeline.fit(X_train, y_train)
#                 y_pred = pipeline.predict(X_test)
#                 y_prob = pipeline.predict_proba(X_test)[:, 1]
# 
#                 # Analyse de l'importance des variables
#                 st.subheader("Importance des variables")
# 
#                 # R√©cup√©rer le Random Forest du pipeline
#                 rf = pipeline.named_steps['classifier']
#                 # R√©cup√©rer les noms des features apr√®s transformation
#                 feature_names = []
# 
#                 # Obtenir les noms des caract√©ristiques pour les variables num√©riques
#                 if numerical_cols:
#                     feature_names.extend(numerical_cols)
# 
#                 st.subheader("Facteurs les plus influents")
# 
#                 rf = pipeline.named_steps['classifier']
# 
#                 # D√©finir categorical_cols avant de l'utiliser
#                 categorical_cols = df.select_dtypes(include=['object']).columns.tolist()
#                 if 'TSA' in categorical_cols:
#                     categorical_cols.remove('TSA')
#                 numerical_cols = df.select_dtypes(exclude=['object']).columns.tolist()
# 
#                 # R√©cup√©rer les noms des caract√©ristiques apr√®s transformation
#                 preprocessor = pipeline.named_steps['preprocessor']
#                 cat_features = []
#                 if hasattr(preprocessor.transformers_[1][1], 'get_feature_names_out'):
#                     cat_features = preprocessor.transformers_[1][1].get_feature_names_out(categorical_cols).tolist()
#                 else:
#                     # Fallback si get_feature_names_out n'est pas disponible
#                     for col in categorical_cols:
#                         unique_vals = df[col].unique()
#                         cat_features.extend([f"{col}_{val}" for val in unique_vals[1:]])
# 
#                 all_features = numerical_cols + cat_features
#                 # Si la longueur des noms de caract√©ristiques ne correspond pas √† l'importance
#                 if len(all_features) != len(rf.feature_importances_):
#                     all_features = [f"Feature {i}" for i in range(len(rf.feature_importances_))]
# 
#                 feature_importance = rf.feature_importances_
# 
#                 # Cr√©er DataFrame pour l'importance des variables
#                 importances = rf.feature_importances_
#                 fi_df = pd.DataFrame({
#                     'Feature': all_features,
#                     'Importance': importances
#                 }).sort_values('Importance', ascending=False)
# 
#                 # Afficher l'importance des variables
#                 fig, ax = plt.subplots(figsize=(10, 6))
#                 sns.barplot(
#                     x='Importance',
#                     y='Feature',
#                     data=fi_df.head(15),
#                     orient='h',
#                     palette='viridis'
#                 )
#                 ax.set_title("Contribution des variables √† la pr√©diction")
#                 st.pyplot(fig)
# 
#                 # √âvaluation des performances
#                 st.subheader("√âvaluation compl√®te des performances")
#                 accuracy = accuracy_score(y_test, y_pred)
#                 precision = precision_score(y_test, y_pred)
#                 recall = recall_score(y_test, y_pred)
#                 f1 = f1_score(y_test, y_pred)
#                 auc = roc_auc_score(y_test, y_prob)
# 
#                 col1, col2, col3 = st.columns(3)
#                 with col1:
#                     st.metric("Pr√©cision (Accuracy)", f"{accuracy:.2%}")
#                     st.metric("Rappel (Sensitivity)", f"{recall:.2%}")
#                 with col2:
#                     st.metric("Sp√©cificit√© (Precision)", f"{precision:.2%}")
#                     st.metric("Score F1", f"{f1:.2%}")
#                 with col3:
#                     st.metric("AUC-ROC", f"{auc:.2%}")
#                     st.metric("Erreur", f"{1-accuracy:.2%}")
# 
#                 st.subheader("Matrice de confusion")
#                 cm = confusion_matrix(y_test, y_pred)
#                 fig, ax = plt.subplots(figsize=(8, 6))
#                 sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)
#                 plt.xlabel('Pr√©diction')
#                 plt.ylabel('R√©alit√©')
#                 plt.title('Matrice de confusion')
#                 ax.set_xticklabels(['Non-TSA', 'TSA'])
#                 ax.set_yticklabels(['Non-TSA', 'TSA'])
#                 st.pyplot(fig)
# 
#                 st.subheader("Rapport de classification d√©taill√©")
#                 report = classification_report(y_test, y_pred, output_dict=True)
#                 report_df = pd.DataFrame(report).transpose()
#                 st.dataframe(report_df.style.set_properties(**{'background-color': 'white'}))
# 
#                 st.header("Comparaison avec d'autres algorithmes")
#                 models = {
#                     "R√©gression Logistique": LogisticRegression(random_state=42, max_iter=1000),
#                     "XGBoost": XGBClassifier(random_state=42),
#                     "LightGBM": LGBMClassifier(random_state=42),
#                     "Random Forest": RandomForestClassifier(n_estimators=100, random_state=42)
#                 }
# 
#                 results = []
#                 for name, model in models.items():
#                     # Cr√©er un pipeline pour chaque mod√®le
#                     curr_pipe = Pipeline([
#                         ('preprocessor', preprocessor),
#                         ('classifier', model)
#                     ])
#                     curr_pipe.fit(X_train, y_train)
#                     y_pred_model = curr_pipe.predict(X_test)
#                     acc = accuracy_score(y_test, y_pred_model)
#                     f1score = f1_score(y_test, y_pred_model)
#                     results.append({
#                         'Mod√®le': name,
#                         'Accuracy': acc,
#                         'F1-Score': f1score
#                     })
#                 results_df = pd.DataFrame(results)
#                 st.dataframe(results_df.style.highlight_max(subset=['Accuracy']))
# 
#                 fig, ax = plt.subplots(figsize=(10, 6))
#                 x = np.arange(len(results_df))
#                 width = 0.35
#                 ax.bar(x - width/2, results_df['Accuracy'], width, label='Accuracy')
#                 ax.bar(x + width/2, results_df['F1-Score'], width, label='F1-Score')
#                 ax.set_xticks(x)
#                 ax.set_xticklabels(results_df['Mod√®le'])
#                 ax.legend()
#                 ax.set_ylabel('Score')
#                 ax.set_title('Comparaison des performances des mod√®les')
#                 st.pyplot(fig)
# 
#                 st.markdown("""
#                     ### Analyse comparative des mod√®les
#                     Les diff√©rents algorithmes test√©s pr√©sentent des performances variables:
#                     1. **Random Forest** offre g√©n√©ralement le meilleur √©quilibre entre pr√©cision et robustesse, ce qui explique notre choix pour le mod√®le principal.
#                     2. **XGBoost** montre d'excellentes performances et une grande pr√©cision de classification.
# 
#                     3. **LightGBM** offre un bon compromis entre rapidit√© et pr√©cision, avec des r√©sultats tr√®s proches de XGBoost.
#                     4. **R√©gression Logistique**, malgr√© sa simplicit√©, offre une baseline solide et une meilleure interpr√©tabilit√©.
# 
#                     Le choix final du Random Forest est motiv√© par sa robustesse, sa capacit√© √† g√©rer efficacement les donn√©es mixtes apr√®s transformation par le pr√©processeur, et sa r√©sistance au surapprentissage.
#                 """)
#         except Exception as e:
#             st.error(f"Erreur lors de la mod√©lisation : {str(e)}")
#             st.info("V√©rifiez que la pr√©paration des donn√©es a √©t√© effectu√©e correctement.")
# 
# elif "üìù Test AQ-10" in selection:
#     st.markdown(
#         f"""<div class="header-container">
#             <span style="font-size:2.5rem">üìù</span>
#             <h1 class="app-title">Test AQ-10</h1>
#         </div>""", unsafe_allow_html=True
#     )
# 
#     image_url = "https://drive.google.com/file/d/1c2RrCChdmOv9IsGRY_T0i0QOgNB-oHt0/view?usp=sharing"
#     st.markdown(get_img_with_href(image_url, "#", as_banner=True), unsafe_allow_html=True)
# 
#     st.markdown('<p class="questionnaire-title">Questionnaire AQ-10</p>', unsafe_allow_html=True)
#     st.markdown("""
#     Ce questionnaire aide √† √©valuer les traits autistiques potentiels. R√©pondez de mani√®re aussi honn√™te que possible.
#     Les r√©ponses ne sont pas stock√©es et servent uniquement √† l'analyse.
#     """)
# 
#     # Initialisation du dictionnaire pour stocker les r√©ponses
#     if "aq10_answers" not in st.session_state:
#         st.session_state.aq10_answers = {}
# 
#     # Questions avec leur syst√®me de scoring
#     questions = [
#         {"question": "üëÇ 1. Je remarque souvent de petits bruits que les autres ne remarquent pas.",
#          "scoring": {"Tout √† fait d'accord": 1, "Plut√¥t d'accord": 1, "Plut√¥t pas d'accord": 0, "Pas du tout d'accord": 0}},
#         {"question": "üîç 2. Je me concentre g√©n√©ralement davantage sur l'ensemble que sur les petits d√©tails.",
#          "scoring": {"Tout √† fait d'accord": 0, "Plut√¥t d'accord": 0, "Plut√¥t pas d'accord": 1, "Pas du tout d'accord": 1}},
#         {"question": "üîÑ 3. Je trouve facile de faire plusieurs choses en m√™me temps.",
#          "scoring": {"Tout √† fait d'accord": 0, "Plut√¥t d'accord": 0, "Plut√¥t pas d'accord": 1, "Pas du tout d'accord": 1}},
#         {"question": "‚èØÔ∏è 4. S'il y a une interruption, je peux rapidement reprendre ce que je faisais.",
#          "scoring": {"Tout √† fait d'accord": 0, "Plut√¥t d'accord": 0, "Plut√¥t pas d'accord": 1, "Pas du tout d'accord": 1}},
#         {"question": "üóØÔ∏è 5. Je trouve facile de ¬´ lire entre les lignes ¬ª quand quelqu'un me parle.",
#          "scoring": {"Tout √† fait d'accord": 0, "Plut√¥t d'accord": 0, "Plut√¥t pas d'accord": 1, "Pas du tout d'accord": 1}},
#         {"question": "üò¥ 6. Je sais comment savoir si la personne qui m'√©coute commence √† s'ennuyer.",
#          "scoring": {"Tout √† fait d'accord": 0, "Plut√¥t d'accord": 0, "Plut√¥t pas d'accord": 1, "Pas du tout d'accord": 1}},
#         {"question": "üìö 7. Quand je lis une histoire, j'ai du mal √† comprendre les intentions des personnages.",
#          "scoring": {"Tout √† fait d'accord": 1, "Plut√¥t d'accord": 1, "Plut√¥t pas d'accord": 0, "Pas du tout d'accord": 0}},
#         {"question": "üóÇÔ∏è 8. J'aime collecter des informations sur des cat√©gories de choses (par exemple : types de voitures, d'oiseaux, de trains, de plantes, etc.).",
#          "scoring": {"Tout √† fait d'accord": 1, "Plut√¥t d'accord": 1, "Plut√¥t pas d'accord": 0, "Pas du tout d'accord": 0}},
#         {"question": "üòä 9. Je trouve facile de comprendre ce que quelqu'un pense ou ressent rien qu'en regardant son visage.",
#          "scoring": {"Tout √† fait d'accord": 0, "Plut√¥t d'accord": 0, "Plut√¥t pas d'accord": 1, "Pas du tout d'accord": 1}},
#         {"question": "‚ùì 10. J'ai du mal √† comprendre les intentions des gens.",
#          "scoring": {"Tout √† fait d'accord": 1, "Plut√¥t d'accord": 1, "Plut√¥t pas d'accord": 0, "Pas du tout d'accord": 0}}
#     ]
# 
#     # Stockage des r√©ponses
#     responses = []
# 
#     # Pour chaque question
#     for i, q in enumerate(questions):
#         options = list(q["scoring"].keys())
#         question_key = f"aq10_question_{i}"
# 
#         # Afficher la question
#         st.markdown(f'<div class="question-container"><p class="question-text">{q["question"]}</p>', unsafe_allow_html=True)
# 
#         # Si cette question n'a pas encore de r√©ponse, initialiser avec une valeur par d√©faut
#         if question_key not in st.session_state:
#             st.session_state[question_key] = options[0]
# 
#         # Trouver l'index de la r√©ponse actuelle dans session_state
#         if st.session_state[question_key] in options:
#             default_index = options.index(st.session_state[question_key])
#         else:
#             default_index = 0
# 
#         # Radio button avec la valeur pr√©c√©demment s√©lectionn√©e
#         selected_response = st.radio(
#             "",
#             options,
#             key=f"radio_{i}",
#             index=default_index,
#             label_visibility="collapsed",
#             horizontal=True
#         )
# 
#         # Mettre √† jour session_state avec la nouvelle s√©lection
#         st.session_state[question_key] = selected_response
# 
#         # Ajouter le score √† la liste des r√©ponses
#         responses.append(q["scoring"][selected_response])
# 
#         st.markdown('</div>', unsafe_allow_html=True)
# 
#     # Bouton pour calculer le score
#     col1, col2, col3 = st.columns([1, 2, 1])
#     with col2:
#         calculate_button = st.button("Calculer mon score", use_container_width=True)
# 
#     if calculate_button:
#         total = sum(responses)
#         st.session_state.aq10_total = total
#         st.session_state.aq10_responses = responses
# 
#         result_col1, result_col2, result_col3 = st.columns([1, 3, 1])
#         with result_col2:
#             st.markdown(f"""
#             <div style="background-color: white; padding: 25px; border-radius: 12px; box-shadow: 0 4px 10px rgba(0,0,0,0.1); text-align: center; margin-top: 20px;">
#                 <h2 style="margin-bottom: 15px; color: #3498db;">R√©sultat : {total}/10</h2>
#                 <div style="height: 5px; background: linear-gradient(90deg, #3498db {total*10}%, #e0e0e0 {total*10}%); border-radius: 10px; margin-bottom: 20px;"></div>
#                 {"<p style='color: #e74c3c; font-size: 1.1rem;'><strong>Il serait recommand√© de consulter un professionnel</strong><br>Un score de 6 ou plus indique qu'une √©valuation approfondie par un sp√©cialiste de l'autisme pourrait √™tre b√©n√©fique.</p>" if total >= 6 else "<p style='color: #2ecc71; font-size: 1.1rem;'><strong>Aucun signe √©vident de traits autistiques</strong><br>Ce score sugg√®re qu'une √©valuation compl√©mentaire n'est pas n√©cessaire selon ce test.</p>"}
#                 <p style="font-size: 0.9rem; color: #7f8c8d; margin-top: 15px;"><em>Ce questionnaire est un outil de d√©pistage rapide bas√© sur l'AQ-10 d√©velopp√© par l'Universit√© de Cambridge.</em></p>
#             </div>
#             """, unsafe_allow_html=True)
# 
# 
# elif "ü§ñ Pr√©diction par IA" in selection:
#     current_page = "Pr√©diction par IA"
#     st.markdown(
#         f"""<div class="header-container">
#             <span style="font-size:2.5rem">ü§ñ</span>
#             <h1 class="app-title">Pr√©dire et expliquer le risque de TSA</h1>
#         </div>""", unsafe_allow_html=True
#     )
# 
#     # Import de plotly pour des visualisations robustes
#     import plotly.graph_objects as go
#     import plotly.express as px
# 
#     @st.cache_resource
#     def train_advanced_model():
#         if df.empty:
#             return None, None, None
# 
#         df_model = df.copy()
#         if 'Jaunisse' in df_model.columns:
#             df_model = df_model.drop(columns=['Jaunisse'])
#         # S√©parer les variables num√©riques et cat√©gorielles
#         categorical_cols = df_model.select_dtypes(include=['object']).columns.tolist()
#         if 'TSA' in categorical_cols:
#             categorical_cols.remove('TSA')
#         numerical_cols = df_model.select_dtypes(exclude=['object']).columns.tolist()
#         # D√©finir le pr√©processeur pour les donn√©es mixtes avec remainder='passthrough'
#         preprocessor = ColumnTransformer(
#             transformers=[
#                 ('num', StandardScaler(), numerical_cols),
#                 ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)
#             ],
#             remainder='passthrough',  # Conserver les colonnes non sp√©cifi√©es
#             verbose_feature_names_out=False
#         )
# 
#         X = df_model.drop(columns=['TSA'])
#         y = df_model['TSA'].map({'Yes': 1, 'No': 0})
# 
#         try:
#             # Random Forest avec moins d'estimateurs pour acc√©l√©rer le traitement
#             rf_model = RandomForestClassifier(
#                 n_estimators=50,  # R√©duit pour Google Colab
#                 max_depth=8,
#                 min_samples_split=10,
#                 min_samples_leaf=2,
#                 max_features='sqrt',  # Pour acc√©l√©rer
#                 random_state=42,
#                 n_jobs=-1  # Utiliser tous les c≈ìurs disponibles
#             )
# 
#             # Pr√©traiter X pour obtenir les noms de features transform√©s
#             X_processed = preprocessor.fit_transform(X)
# 
#             # Entra√Æner le mod√®le s√©par√©ment
#             rf_model.fit(X_processed, y)
# 
#             # Retourner les composants
#             return rf_model, preprocessor, X.columns.tolist()
#         except Exception as e:
#             st.error(f"Erreur lors de l'entra√Ænement du mod√®le: {str(e)}")
#             return None, None, None
# 
#     # Fonction pour cr√©er la visualisation horizontale avec le risque
#     def create_risk_visualization(risk_percentage):
#         # Cr√©er la figure
#         fig = go.Figure()
# 
#         # Ajouter une barre horizontale de 0 √† 100%
#         fig.add_trace(go.Bar(
#             y=["Risque de TSA"],
#             x=[100],  # La barre couvre tout (0-100%)
#             marker=dict(
#                 color='green',
#                 line=dict(color='green', width=1)
#             ),
#             orientation='h',
#             showlegend=False,
#             hoverinfo='none'
#         ))
# 
#         # Ajouter une ligne verticale √† la position du risque
#         fig.add_shape(
#             type="line",
#             x0=risk_percentage,
#             y0=-0.4,  # Positionnement vertical pour centrer sur la barre
#             x1=risk_percentage,
#             y1=0.4,   # Positionnement vertical pour centrer sur la barre
#             line=dict(
#                 color="red",
#                 width=3,
#                 dash="solid",
#             )
#         )
# 
#         # Ajouter l'annotation pour le risque
#         fig.add_annotation(
#             x=risk_percentage,
#             y=0,
#             text=f"{risk_percentage:.2f}%",
#             showarrow=True,
#             arrowhead=2,
#             arrowsize=1,
#             arrowwidth=2,
#             arrowcolor="red",
#             ax=0,
#             ay=-30
#         )
# 
#         # Configurer la mise en page
#         fig.update_layout(
#             xaxis=dict(
#                 title="Pourcentage",
#                 range=[0, 100],  # √âchelle de 0 √† 100%
#                 tickvals=[0, 25, 50, 75, 100],
#                 ticktext=["0%", "25%", "50%", "75%", "100%"]
#             ),
#             yaxis=dict(
#                 showticklabels=False
#             ),
#             height=150,
#             margin=dict(l=20, r=20, t=20, b=20),
#             paper_bgcolor='rgba(0,0,0,0)',
#             plot_bgcolor='rgba(0,0,0,0)'
#         )
# 
#         return fig
# 
#     if not df.empty:
#         with st.spinner("Pr√©paration du mod√®le..."):
#             model, preprocessor, feature_names = train_advanced_model()
# 
#         st.subheader("Informations personnelles pour la pr√©diction")
#         col1, col2 = st.columns(2)
#         with col1:
#             age = st.number_input("√Çge", min_value=1, max_value=100, value=30)
#             genres = df['Genre'].unique().tolist()
#             genre = st.selectbox("Genre", options=genres)
#             has_family_asd = st.selectbox("Cas d'autisme dans la famille", options=["Yes", "No"], index=1)
# 
#             # Ajout de la variable statut_testeur
#             statut_options = ["Individu", "Parent", "Famille", "Professionnel", "Autre"]
#             statut_testeur = st.selectbox("Qui compl√®te le questionnaire?", options=statut_options, index=0,
#                                         help="Indique la personne qui remplit le questionnaire (vous-m√™me, un parent, etc.)")
# 
#             if 'Ethnie' in df.columns:
#                 ethnies = df['Ethnie'].dropna().unique().tolist()
#                 ethnie = st.selectbox("Ethnie", options=ethnies)
#         with col2:
#             if st.session_state.aq10_total > 0:
#                 st.info(f"Votre score AQ-10 : {st.session_state.aq10_total}/10")
#                 st.info("Vos r√©ponses du test AQ-10 seront utilis√©es pour la pr√©diction")
#                 use_aq10_responses = True
#             else:
#                 st.warning("Vous n'avez pas compl√©t√© le questionnaire AQ-10")
#                 st.info("Vous pouvez saisir manuellement vos r√©ponses ci-dessous")
#                 use_aq10_responses = False
#                 aq_responses = {}
#                 for i in range(1, 11):
#                     aq_responses[f'A{i}'] = st.selectbox(
#                         f"Question A{i}", options=[0, 1], index=0, help="0 = Non, 1 = Oui"
#                     )
# 
#         if st.button("Pr√©dire et expliquer le risque de TSA", key="predict_button"):
#             if model and preprocessor:
#                 try:
#                     # Cr√©er un dataframe pour la pr√©diction
#                     test_data = {
#                         'Age': [int(age)],
#                         'Genre': [genre],
#                         'Autisme_familial': [has_family_asd],
#                         'Statut_testeur': [statut_testeur]  # Ajout du statut_testeur
#                     }
# 
#                     # Ajouter l'ethnie si pr√©sente
#                     if 'Ethnie' in df.columns:
#                         test_data['Ethnie'] = [ethnie]
# 
#                     # Ajouter les r√©ponses aux questions A1-A10
#                     if use_aq10_responses:
#                         aq_responses = st.session_state.get("aq10_responses", None)
#                         if aq_responses is not None:
#                             for i, response in enumerate(aq_responses):
#                                 test_data[f'A{i+1}'] = [response]
#                             test_data['Score_A10'] = [sum(aq_responses)]
#                         else:
#                             st.error("Les r√©ponses AQ-10 ne sont pas disponibles. Merci de compl√©ter le test AQ-10 avant la pr√©diction.")
#                             st.stop()
# 
#                     else:
#                         # Utiliser les r√©ponses saisies manuellement
#                         for i in range(1, 11):
#                             test_data[f'A{i}'] = [aq_responses[f'A{i}']]
# 
#                         # Calculer le Score_A10 comme somme des r√©ponses
#                         test_data['Score_A10'] = [sum(aq_responses.values())]
# 
#                     # Cr√©er le dataframe de test
#                     test_df = pd.DataFrame(test_data)
# 
#                     # Pr√©traiter les donn√©es
#                     X_test_processed = preprocessor.transform(test_df)
# 
#                     # Pr√©diction de probabilit√©
#                     y_prob = model.predict_proba(X_test_processed)[0, 1]
# 
#                     # Convertir en pourcentage
#                     risk_percentage = y_prob * 100
# 
#                     # Afficher le r√©sultat
#                     st.header("R√©sultat de la pr√©diction")
# 
# 
#                     st.markdown(f"### Probabilit√© de TSA: {risk_percentage:.2f}%")
# 
# 
#                     risk_fig = create_risk_visualization(risk_percentage)
#                     st.plotly_chart(risk_fig, use_container_width=True)
# 
# 
#                     col1, col2 = st.columns(2)
#                     with col1:
#                         st.markdown("#### Probabilit√© de TSA")
# 
#                         risk_color = "red" if risk_percentage > 50 else "green"
# 
# 
#                         st.markdown(f"<h2 style='color: {risk_color};'>{risk_percentage:.2f}%</h2>", unsafe_allow_html=True)
# 
#                     with col2:
#                         st.markdown("#### Score AQ-10")
#                         score_value = test_data['Score_A10'][0]
#                         st.metric(
#                             "Score",
#                             f"{score_value}/10",
#                             delta=f"{score_value - 5}" if score_value != 5 else "Seuil critique",
#                             delta_color="inverse" if score_value > 5 else "normal"
#                         )
# 
#                     # Explication des r√©sultats
#                     st.subheader("Explication du r√©sultat")
#                     st.markdown(f"""
#                     Le mod√®le Random Forest a analys√© vos r√©ponses et vos informations personnelles pour
#                     √©valuer le risque de Trouble du Spectre Autistique (TSA). Cette √©valuation est bas√©e
#                     sur un mod√®le entra√Æn√© avec des donn√©es de plus de 5000 personnes.
# 
#                     {'**Risque √©lev√© d√©tect√©** : Le score de probabilit√© de {risk_percentage:.2f}% indique un risque significatif. Une consultation avec un sp√©cialiste est recommand√©e.' if risk_percentage > 60 else ''}
#                     {'**Risque mod√©r√© d√©tect√©** : Le score de probabilit√© de {risk_percentage:.2f}% indique un risque mod√©r√©. Un suivi pourrait √™tre b√©n√©fique.' if 40 <= risk_percentage <= 60 else ''}
#                     {'**Risque faible d√©tect√©** : Le score de probabilit√© de {risk_percentage:.2f}% indique un risque faible. Aucune action imm√©diate''est n√©cessaire.' if risk_percentage < 40 else ''}
#                     **Rappel important :** Cette pr√©diction est un outil d'aide et ne remplace pas un diagnostic m√©dical professionnel.
#                     """)
# 
#                     # MODIFICATION 2: Ajouter des visuels pertinents des variables les plus importantes
#                     st.subheader("Facteurs les plus influents")
# 
#                     # R√©cup√©rer les importances des variables
#                     feature_importances = model.feature_importances_
# 
#                     # Obtenir les noms des features apr√®s transformation
#                     if hasattr(preprocessor, 'get_feature_names_out'):
#                         feature_names = preprocessor.get_feature_names_out()
#                     else:
#                         # Alternative si get_feature_names_out n'est pas disponible
#                         feature_names = test_df.columns.tolist()
#                         # Assurer que la longueur correspond
#                         if len(feature_names) != len(feature_importances):
#                             feature_names = [f"Feature {i}" for i in range(len(feature_importances))]
# 
#                     # Cr√©er un DataFrame pour l'importance des variables
#                     importance_df = pd.DataFrame({
#                         'Variable': feature_names,
#                         'Importance': feature_importances
#                     }).sort_values('Importance', ascending=False).head(10)
# 
#                     # Cr√©er la visualisation
#                     fig = px.bar(
#                         importance_df,
#                         x='Importance',
#                         y='Variable',
#                         orientation='h',
#                         color='Importance',
#                         color_continuous_scale='Blues',
#                         title="Contribution des variables √† la pr√©diction du TSA"
#                     )
#                     fig.update_layout(
#                         xaxis_title="Importance relative",
#                         yaxis_title="Variables",
#                         height=500,
#                         margin=dict(l=20, r=20, t=40, b=20)
#                     )
# 
#                     st.plotly_chart(fig, use_container_width=True)
# 
#                     # Ajouter une explication d√©taill√©e des variables
#                     st.markdown("""
#                     ### Explication d√©taill√©e des variables importantes
# 
#                     #### Score AQ-10
#                     Le score total au questionnaire est l'indicateur le plus puissant. Ce score synth√©tise l'ensemble des r√©ponses
#                     et repr√©sente un indicateur valid√© cliniquement pour le d√©pistage des TSA.
# 
#                     #### Questions individuelles (A1-A10)
#                     - **Questions A5, A6, A9**: Ces questions √©valuent sp√©cifiquement la compr√©hension sociale et la capacit√© √†
#                       interpr√©ter les √©motions d'autrui, domaine particuli√®rement affect√© dans les TSA.
#                     - **Questions A1, A8**: Ces questions mesurent l'attention aux d√©tails et les int√©r√™ts restreints,
#                       caract√©ristiques fr√©quentes des profils autistiques.
# 
#                     #### Facteurs d√©mographiques
#                     - **√Çge**: L'√¢ge influence la manifestation des traits autistiques et leur impact sur la vie quotidienne.
#                       Les strat√©gies compensatoires peuvent se d√©velopper avec l'√¢ge.
#                     - **Genre**: Le ratio masculin/f√©minin observ√© dans l'autisme est d'environ 3:1, ce qui explique
#                       l'importance mod√©r√©e de cette variable.
# 
#                     #### Facteurs contextuels
#                     - **Ant√©c√©dents familiaux**: La composante g√©n√©tique des TSA est significative, avec un risque plus
#                       √©lev√© lorsqu'un membre de la famille proche est concern√©.
#                     - **Statut du testeur**: La personne qui remplit le questionnaire peut influencer les r√©ponses et donc
#                       le r√©sultat final.
# 
#                     Cette analyse est bas√©e uniquement sur le mod√®le Random Forest sans recourir √† des biblioth√®ques
#                     d'explicabilit√© comme SHAP ou LIME.
#                     """)
# 
#                 except Exception as e:
#                     st.error(f"Erreur lors de la pr√©diction: {str(e)}")
#                     st.info("Veuillez v√©rifier que toutes les informations ont √©t√© correctement saisies.")
#             else:
#                 st.error("Le mod√®le n'a pas pu √™tre charg√©. Veuillez rafra√Æchir la page et r√©essayer.")
# 
# elif "üìö Documentation" in selection:
#     current_page = "Documentation"
#     st.markdown("""
#     <div class="header-container">
#         <span style="font-size:2.5rem">üìö</span>
#         <h1 class="app-title">Documentation</h1>
#     </div>
#     """, unsafe_allow_html=True)
# 
#     st.markdown("""
#     ## Documentation du projet TSA
# 
#     Cette documentation d√©taille les composants techniques et scientifiques de notre application d'analyse des Troubles du Spectre Autistique (TSA).
# 
#     ### 1. Sources de donn√©es
# 
#     Nos donn√©es proviennent de cinq sources diff√©rentes:
#     - L'universit√© de l'Arkansas (donn√©es nord-am√©ricaines)
#     - Deux √©tudes du Manukau Institute of Technology (Nouvelle-Z√©lande) sur enfants et adultes
#     - Un jeu de donn√©es d'Arabie Saoudite (506 sujets)
#     - Un jeu mondial de 800 sujets
# 
#     Au total, 5049 sujets composent notre dataset final apr√®s concat√©nation et uniformisation.
# 
#     ### 2. Pr√©traitement des donn√©es
# 
#     Le processus de nettoyage inclut:
#     - Standardisation des noms de colonnes
#     - Encodage des variables cat√©gorielles
#     - Traitement des valeurs manquantes
#     - Cr√©ation de la variable Score_A10 (somme des r√©ponses aux questions A1-A10)
# 
#     ### 3. Mod√©lisation
#     Notre approche de mod√©lisation s'est d√©roul√©e en plusieurs √©tapes:
# 
#     1. **Analyse exploratoire** : FAMD pour visualiser les donn√©es et comprendre les relations
#     2. **Mod√®le s√©lectionn√©** : Random Forest Classifier
#     3. **Optimisation** : GridSearchCV pour l'ajustement des hyperparam√®tres:
#        - max_depth: 10
#        - max_features: None
#        - min_samples_leaf: 1
#        - min_samples_split: 10
#        - n_estimators: 100
#     4. **M√©triques de performance**:
#        - Accuracy: 96.03%
#        - Precision: 95.39%
#        - Recall: 95.71%
#        - F1 Score: 95.71%
# 
#     ### 4. Variables importantes
# 
#     D'apr√®s l'analyse du mod√®le, les variables les plus pr√©dictives sont:
#     1. **Score_A10** : Score total au questionnaire (impact majeur)
#     2. **Statut_testeur_Individu** : Si la personne √©valu√©e remplit elle-m√™me le questionnaire
#     3. **Age** : √Çge de la personne √©valu√©e
#     4. **Ethnie_WHITE_EUROPEAN** : Appartenance √† ce groupe ethnique
#     5. **Ant√©c√©dents familiaux** : Pr√©sence d'autisme dans la famille
# 
#     ### 5. Utilisation de l'application
# 
#     1. **Test AQ-10** : Questionnaire standardis√© de 10 questions
#     2. **Pr√©diction IA** : Utilisation du mod√®le Random Forest pour pr√©dire le risque de TSA
#     3. **Exploration des donn√©es** : Visualisations interactives pour explorer les relations
# 
#     ### 6. Ressources techniques
# 
#     L'application est d√©velopp√©e avec:
#     - **Streamlit** : Pour l'interface utilisateur
#     - **Scikit-learn** : Pour les mod√®les de machine learning
#     - **Plotly** : Pour les visualisations interactives
#     - **Pandas & NumPy** : Pour la manipulation de donn√©es
# 
#     ### 7. Consid√©rations √©thiques
#     Notre application est un **outil d'aide √† la d√©cision** et non un dispositif de diagnostic m√©dical. Les r√©sultats doivent toujours √™tre interpr√©t√©s par des professionnels de sant√© qualifi√©s.
#     """)
# 
# 
#     st.markdown("---")
#     st.header("Ressources sur les Troubles du Spectre Autistique (TSA)")
# 
#     tab1, tab2, tab3 = st.tabs(["Livres r√©cents", "Sites web et articles", "Vid√©os √©ducatives"])
# 
#     with tab1:
#         st.markdown("""
#         ### Ouvrages r√©cents (2024-2025)
# 
#         | Titre | Auteur(s) | Date de publication | Description |
#         |-------|-----------|---------------------|-------------|
#         | **Vivre avec un TSA, Les troubles du spectre autistique** | Elise Couval, Corinne Fr√©ville | Juin 2024 | Guide pratique sur la vie quotidienne avec TSA |
#         | **Comment pense une personne autiste ?** | | Avril 2025 | Exploration des m√©canismes cognitifs sp√©cifiques aux personnes autistes |
#         | **Des pierres, ils ont fait des √©toiles** | | Septembre 2024 | Approche po√©tique et humaine de l'autisme |
#         | **L'autisme expliqu√© aux non autistes** | Brigitte Harrison, Lise St-Charles | Janvier 2020 | 50 questions pour mieux comprendre et accompagner |
#         | **100 id√©es pour accompagner un enfant avec autisme** | Ren√© Pry | | Aborde la r√©alit√© des 120 000 enfants et adultes autistes en France |
#         """)
# 
#         st.info("Ces livres sont disponibles dans la plupart des librairies sp√©cialis√©es ou en ligne.")
# 
#     with tab2:
#         st.markdown("""
#         ### Sites web de r√©f√©rence
# 
#         - [Autisme Info Service](https://www.autismeinfoservice.fr/informer/autisme/tsa) - Portail d'information officiel sur les TSA
#         - [Bibliosante - Cahier TSA 2024](https://bibliosante.ca/cahiers/cahier_spectre_autisme_2024.pdf) - Guide complet sur les TSA (√©dition 2024)
#         - [Sensibilisation TSA - Mise √† jour 2024](https://www.calameo.com/books/0050508852a91c25d23a3) - Bibliographie actualis√©e
# 
#         ### Articles scientifiques r√©cents
# 
#         - **Avanc√©es en neuroimagerie des TSA** (2024) - Revue des derni√®res d√©couvertes sur les biomarqueurs c√©r√©braux
#         - **Interventions pr√©coces et plasticit√© c√©r√©brale** (2025) - Impact des prises en charge avant 3 ans
#         - **Outils num√©riques d'aide au diagnostic** (2025) - √âtat de l'art des applications d'IA pour le d√©pistage
#         """)
# 
#         st.warning("""
#         **Attention aux fausses informations**: L'id√©e selon laquelle l'autisme serait caus√© par les vaccins est
#         r√©guli√®rement d√©mentie par la communaut√© scientifique. Des films comme "Vaxxed" propagent des th√©ories
#         conspirationnistes bas√©es sur une √©tude frauduleuse et retir√©e.
#         """)
# 
#     with tab3:
#         st.markdown("""
#         ### Vid√©os √©ducatives
# 
#         1. **[Comprendre l'autisme en 10 minutes](https://www.youtube.com/)**
#            Une vid√©o claire et concise expliquant les bases du TSA.
# 
#         2. **[T√©moignages: Vivre avec l'autisme](https://www.youtube.com/)**
#            Des personnes autistes partagent leurs exp√©riences quotidiennes.
# 
#         3. **[Les avanc√©es de la recherche sur l'autisme en 2025](https://www.youtube.com/)**
#            Un r√©sum√© des derni√®res d√©couvertes scientifiques.
# 
#         4. **[Inclusion scolaire des enfants TSA](https://www.youtube.com/)**
#            Strat√©gies p√©dagogiques adapt√©es et t√©moignages d'enseignants.
# 
#         > *Remplacez les liens fictifs par des liens r√©els vers des vid√©os pertinentes.*
#         """)
# 
# elif "‚ÑπÔ∏è √Ä propos" in selection:
#     current_page = "√Ä propos"
#     st.markdown("""
#     <div class="header-container">
#         <span style="font-size:2.5rem">‚ÑπÔ∏è</span>
#         <h1 class="app-title">√Ä propos</h1>
#     </div>
#     """, unsafe_allow_html=True)
# 
#     st.markdown("""
#     ## √Ä propos du projet
# 
#     Ce projet a √©t√© r√©alis√© dans le cadre d'une √©tude sur les m√©thodes de d√©pistage des Troubles du Spectre Autistique (TSA).
# 
#     ### √âquipe de Projet
# 
#     **Auteurs :**
#     - Alexandre Bernard
#     - R√©mi Chenouri
#     - Ahmed Ibnabasse
#     - Laurence Souppayaraza
# 
#     ### Objectifs du Projet
# 
#     1. Identifier les facteurs associ√©s √† la pr√©sence d'un TSA
#     2. Explorer les donn√©es pour d√©celer des tendances et biais
#     3. Construire des mod√®les pr√©dictifs pour l'√©valuation du TSA
#     ### Remerciements
# 
#     Nous remercions toutes les personnes ayant contribu√© √† ce projet, en particulier notre mentor Yohan Cohen pour son soutien et ses conseils pr√©cieux.
# 
#     ### Contact
# 
#     Pour toute question concernant ce projet, veuillez nous contacter √† l'adresse suivante:
#     [contact@projet-autisme.org](mailto:contact@projet-autisme.org)""")
# 
#     st.markdown("""
#     ### Licence
#     Cette application est mise √† disposition sous licence open-source. Le code et les donn√©es anonymis√©es sont disponibles pour des fins de recherche uniquement.""")
# 
#     image_url = "https://drive.google.com/file/d/1tbARR43xi1GCnfY9XrEc-O2FbMnTmPcW/view?usp=sharing"
#     st.markdown(get_img_with_href(image_url, "#", as_banner=False), unsafe_allow_html=True)
# 
# 
#     st.markdown("""
#     &copy; 2025 - Projet Autisme - Tous droits r√©serv√©s
#     """)

public_url = ngrok.connect(8501)
print(public_url)

!streamlit run Streamlit-Autisme.py &